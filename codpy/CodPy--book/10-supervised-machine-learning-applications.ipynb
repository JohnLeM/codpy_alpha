{
 "cells": [
  {
   "cell_type": "raw",
   "id": "07359297",
   "metadata": {},
   "source": [
    "---\n",
    "output:\n",
    "  html_document: default\n",
    "  pdf_document:\n",
    "    keep_tex: yes\n",
    "    includes:\n",
    "      in_header: preamble.tex\n",
    "  word_document: default\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b30793",
   "metadata": {
    "code": "#R_CODE#xfun::read_utf8('preamble.R')",
    "tags": [
     "remove_cell",
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "%%R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78427542",
   "metadata": {
    "tags": [
     "remove_input",
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "from preamble import *\n",
    "import tensorflow as tf\n",
    "plt.close('all')\n",
    "from clusteringCHK import *\n",
    "from housing_prices import *\n",
    "codpy_param = {'rescale:xmax': 1000,\n",
    "'rescale:seed':42,\n",
    "'sharp_discrepancy:xmax':1000,\n",
    "'sharp_discrepancy:seed':30,\n",
    "'sharp_discrepancy:itermax':5,\n",
    "'discrepancy:xmax':500,\n",
    "'discrepancy:ymax':500,\n",
    "'discrepancy:zmax':500,\n",
    "'discrepancy:nmax':2000,\n",
    "'validator_compute': ['accuracy_score','discrepancy_error','norm']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf652fc",
   "metadata": {},
   "source": [
    "# Application to supervised machine learning \n",
    "In this chapter and the following ones, we present some examples of more concrete learning machines problems. Some of these tests are taken from  [kaggle, see this url](https://www.kaggle.com/).\n",
    "\n",
    "Supervised learning problems can be split into Regression and Classification problems. Both problems have as goal the construction of a model that can predict the value of the output from the input variables. In the case of regression the output is a real valued variable, whereas in the case of classification the output is category (e.g. \"disease\" or \"no disease\"). Codpy's extrapolate and projection function can be used to treat each of above mentioned problems.\n",
    "\n",
    "We present two cases corresponding two each typical problems in supervised learning: Boston housing prices prediction and MNIST classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8612266d",
   "metadata": {},
   "source": [
    "## Regression problem: housing price prediction\n",
    "\n",
    "This dataset contains information collected by the U.S Census Service concerning housing in the area of Boston Mass. There are 506 cases and 13 attributes (features) with a target column (price). More details can be found in the article published by Harrison, D. and Rubinfeld, D.L. \"Hedonic prices and the demand for clean air\", J. Environ. Economics & Management, vol.5, 81-102, 1978.\n",
    "\n",
    "### Codpy's extrapolation\n",
    "\n",
    "Starting from the training set $x \\in \\RR^{N_x \\times D}$, we extrapolate the labels $f_z$, and compare to test set labels $f(z)$, using the extrapolation operator defined in \\@ref(eq:EI)-left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43380d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_kernel = kernel_setters.kernel_helper(kernel_setters.set_tensornorm_kernel, 2,1e-8 ,map_setters.set_unitcube_map)\n",
    "data_generator_ = Boston_data_generator()\n",
    "x, fx, x, fx, z, fz = data_generator_.get_data(-1, -1, -1, -1)\n",
    "length_ = len(x)\n",
    "scenarios_list = [ (-1, i, i, -1)  for i in np.arange(length_,20,-(length_-20)/10) ]\n",
    "#scenarios_list = [ (-1, 2**(i), -1, 2**(i))  for i in np.arange(5,9,1) ]\n",
    "scenarios = scenario_generator()\n",
    "scenarios.run_scenarios(scenarios_list,data_generator_, housing_codpy_extrapolator(set_kernel = set_kernel), data_accumulator(), **codpy_param)\n",
    "results = scenarios.accumulator.get_output_datas().dropna(axis=1).T\n",
    "df_results = results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab306e14",
   "metadata": {},
   "source": [
    "We output at table \\@ref(tab:669) the list of performance indicators for this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9893e3e",
   "metadata": {
    "label": 669,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results,  caption = \"Codpy: indicators for Boston housing prices\")%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0588255",
   "metadata": {},
   "source": [
    "### Tensorflow\n",
    "\n",
    "The benchmark method is described chapter \\@ref(a-quick-tour-to-machine-learning). The following lines defines a standard neural network for a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a399fd",
   "metadata": {
    "echo": true,
    "include": true,
    "show": true
   },
   "outputs": [],
   "source": [
    "tf_param = {'tfRegressor': {'epochs': 50,\n",
    "'batch_size':16,\n",
    "'validation_split':0.1,\n",
    "'loss':tf.keras.losses.mean_squared_error,\n",
    "'optimizer':tf.keras.optimizers.Adam(0.001),\n",
    "'layers':[8,64,64,1],\n",
    "'activation':['relu','relu','relu','linear'],\n",
    "'metrics':['mse']}\n",
    "}\n",
    "scenarios.run_scenarios(scenarios_list,data_generator_, tfRegressor(set_kernel = set_kernel), data_accumulator(), **codpy_param,**tf_param)\n",
    "results = scenarios.accumulator.get_output_datas().dropna(axis=1).T\n",
    "df_results = results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0615cfbb",
   "metadata": {},
   "source": [
    "We output at table \\@ref(tab:671) the list of performance indicators for this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd97315",
   "metadata": {
    "label": 671
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results,  caption = \"Tensorflow Neural Network: indicators for Boston housing prices\")%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bde57d4",
   "metadata": {},
   "source": [
    "### Pytorch\n",
    "\n",
    "The Pytorch neural network model is described chapter \\@ref(pytorch-neural-network-model). We use this parameters set to define this Pytorch regression model, defined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa62de85",
   "metadata": {
    "echo": true,
    "include": true,
    "show": true
   },
   "outputs": [],
   "source": [
    "torch_param = {'PytorchRegressor': {'epochs': 50,\n",
    "'layers': [8,64,64],\n",
    "'loss': nn.MSELoss(),\n",
    "'batch_size': 16,\n",
    "'loss': nn.MSELoss(),\n",
    "'activation': nn.ReLU(),\n",
    "'optimizer': torch.optim.Adam,\n",
    "'out_layer': 1}}\n",
    "scenarios.run_scenarios(scenarios_list,data_generator_, PytorchRegressor(set_kernel = set_kernel), data_accumulator(), **codpy_param,**torch_param)\n",
    "results = scenarios.accumulator.get_output_datas().dropna(axis=1).T\n",
    "df_results = pd.concat([df_results,results.T],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f86715",
   "metadata": {},
   "source": [
    "We output at table \\@ref(tab:672) the list of performance indicators for this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2428f892",
   "metadata": {
    "label": 672
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results,  caption = \"Pytorch Neural Network: indicators for Boston housing prices\")%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd344c6",
   "metadata": {},
   "source": [
    "### Decision tree\n",
    "\n",
    "The decision tree model is described chapter \\@ref(decision-tree-model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d10d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios.run_scenarios(scenarios_list,data_generator_, DecisionTreeRegressor(set_kernel = set_kernel), data_accumulator(), **codpy_param)\n",
    "results = scenarios.accumulator.get_output_datas().dropna(axis=1).T\n",
    "df_results = pd.concat([df_results,results.T],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60e1ce6",
   "metadata": {},
   "source": [
    "We output at table \\@ref(tab:673) the list of performance indicators for this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52399e9d",
   "metadata": {
    "label": 673
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results,  caption = \"Decision tree: indicators for Boston housing prices\")%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e2a001",
   "metadata": {},
   "source": [
    "### Methods comparison\n",
    "\n",
    "The following picture compares methods in term of scores Figure \\@ref(fig:309), discrepancy errors Figure \\@ref(fig:310), and execution time Figure \\@ref(fig:311). We give an interpretation of these results.\n",
    "\n",
    "* First notice that the kernel method *codpy lab extra*, that is the extrapolation method, obtains both best scores and worst execution time. \n",
    "* Notice also that one, minus the discrepancy error, matches the scores of the method *codpy lab extra*. This indicates that the discrepancy error is a pertinent indicator.\n",
    "* Another kernel method, *codpy lab proj*, that is the projection method above, is a more balanced method [^268].\n",
    "* Both kernel methods are shipped with a very standard kernel, that is the Gaussian one, that is the only parameter for kernel methods. We emphasize that Kernel engineering can easily improves these results. We do not present these improved kernel methods, as our purposes is to benchmark standard methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe193617",
   "metadata": {
    "fig.cap": "Benchmark scores",
    "label": 360,
    "results": false
   },
   "outputs": [],
   "source": [
    "scenarios.compare_plots(\n",
    "axis_field_labels = [(\"Nx\",\"scores\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9351be80",
   "metadata": {
    "fig.cap": "Discrepancy errors",
    "label": 361,
    "results": false
   },
   "outputs": [],
   "source": [
    "scenarios.compare_plots(\n",
    "axis_field_labels = [(\"Nx\",\"discrepancy_errors\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7264e4b7",
   "metadata": {
    "fig.cap": "Benchmarks execution time",
    "label": 362,
    "lines_to_next_cell": 2,
    "results": false
   },
   "outputs": [],
   "source": [
    "scenarios.compare_plots(\n",
    "axis_field_labels = [(\"Nx\",\"execution_time\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd7dcfb",
   "metadata": {},
   "source": [
    "## Classification problem: handwritten digits\n",
    "\n",
    "This section contains an example of classification for images, which is a typical academic example referred to as the MNIST problem, and allows us to benchmark our results against more popular methods.\n",
    "\n",
    "MNIST (\"Modified National Institute of Standards and Technology\") contains 60,000 training images and 10,000 testing images. Half of the training set and half of the test set were taken from NIST's training dataset, while the other half of the training set and the other half of the test set were taken from NIST's testing dataset. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms.\n",
    "\n",
    "In this section, we propose a benchmark of several machine learning methods, including kernel ones. Our goals, above benchmarking our methods against popular alternatives, are to demonstrate that all these tests are problem dependent, not method dependents. To illustrate this fact, we purposely almost copy paste each test, to test another method. The motivation here is also to provide to our users a bank of code, where they can just copy paste one section of this document to test their own learning machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc721250",
   "metadata": {},
   "source": [
    "### Short introduction to MNIST\n",
    "\n",
    "The MNIST dataset is composed of $60,000$ images defining a training set of handwritten digits. Each image is a vector having dimensions $784$ (a $28 \\times 28$ grayscale image flattened in row-order). There are $10$ digits $0â€“9$. The test set is composed of $10,000$ images with their labels.\n",
    "\n",
    "We formalize the problem as follows. Given the test set represented by a matrix $x\\in \\mathbb{R}^{N_x \\times D}$, $D=784$, the labels $f(x) \\in \\mathbb{R}^{N_x \\times D_f}$, $D_f=10$, and the test set $z\\in \\mathbb{R}^{N_z \\times D}$, $N_z= 10000$, predict the label function $f(z) \\in \\mathbb{R}^{N_z \\times D_f}$. Data are retrieved from Y. LeCun MNIST home page \\cite{YL}, and we will test different values for $N_x$.\n",
    "\n",
    "The following picture shows an image of hand-written number, that is the first image $x^1$, as well as numerous others\n",
    "\n",
    "![](.\\CodPyFigs\\MNIST.png){width=50%}\n",
    "\n",
    "The following line defines our scenario list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ea6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_data_generator_ = MNIST_data_generator()\n",
    "scenarios_list = [ (784, 2**(i), 2**(i-2), 10000)  for i in np.arange(5,9,1)]\n",
    "pd_scenarios_list = pd.DataFrame(scenarios_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ce6348",
   "metadata": {},
   "source": [
    "The table \\@ref(tab:538) output this scenario list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4fe110",
   "metadata": {
    "fig.cap": "scenario list",
    "label": 538,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$pd_scenarios_list, label = \"list of scenari\", col.names = c(\"D\",\"Nx\",\"Ny\",\"Nz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc102627",
   "metadata": {},
   "source": [
    "Scores are computed using the formula \\@ref(eq:score), a scalar in the interval between 0 and 1, which counts the number of correctly predicted images.\n",
    "\n",
    "Our kernel setup for this MNIST test is the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c6cfdf",
   "metadata": {
    "echo": true,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "set_mnist_kernel = kernel_setters.kernel_helper(kernel_setters.set_gaussian_kernel, 0,1e-8 ,map_setters.set_mean_distance_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0c2450",
   "metadata": {},
   "source": [
    "#### Keras Tensorflow scores\n",
    "\n",
    "The benchmark method is described chapter \\@ref(a-quick-tour-to-machine-learning). The following lines defines a standard neural network for studying the MNIST problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad44b29",
   "metadata": {
    "echo": true,
    "include": true,
    "show": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf_param = {'tfClassifier' : {'epochs': 10,\n",
    "'batch_size':16,\n",
    "'validation_split':0.1,\n",
    "'loss': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "'optimizer':tf.keras.optimizers.Adam(0.001),\n",
    "'activation':['relu',''],\n",
    "'layers':[128,10],\n",
    "'metrics':[tf.keras.metrics.SparseCategoricalAccuracy()]} }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da60a0de",
   "metadata": {},
   "source": [
    "We then run the benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00853668",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "scenarios = scenario_generator()\n",
    "scenarios.run_scenarios(scenarios_list,MNIST_data_generator_,tfClassifier(set_kernel = set_mnist_kernel),data_accumulator(),**codpy_param,**tf_param)\n",
    "results = scenarios.accumulator.get_output_datas().dropna(axis=1).T\n",
    "df_results = pd.concat([df_results,results.T],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40b4d86",
   "metadata": {},
   "source": [
    "We output at table \\@ref(tab:574) the list of performance indicators for this test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e215e4",
   "metadata": {
    "fig.cap": "performance indicator for tensorflow",
    "label": 574
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results,  caption = \"tensorflow: indicators for MNIST\")%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80433075",
   "metadata": {},
   "source": [
    "Finally, we output as well the confusion matrix for the last scenario in figure \\@ref(fig:584)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907aaa36",
   "metadata": {
    "fig.cap": "confusion matrix for tensorflow",
    "label": 584
   },
   "outputs": [],
   "source": [
    "multi_plot([scenarios.predictor] ,add_confusion_matrix.plot_confusion_matrix,title='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd24793",
   "metadata": {},
   "source": [
    "#### CodPy scores extrapolation\n",
    "\n",
    "Starting from the training set $x \\in \\RR^{N_x \\times 784}$, we extrapolate the labels $f_z$, and compare to test set labels $f(z)$, using the extrapolation operator defined in \\@ref(eq:EI)-left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397a0ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios.run_scenarios(scenarios_list,MNIST_data_generator_,codpyexClassifier(set_kernel = set_mnist_kernel),data_accumulator(),**codpy_param)\n",
    "results = scenarios.accumulator.get_output_datas().dropna(axis=1).T\n",
    "df_results = pd.concat([df_results,results.T],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb9739d",
   "metadata": {},
   "source": [
    "We output at table \\@ref(tab:594) the list of performance indicators for this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee2b133",
   "metadata": {
    "label": 594
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results,  caption = \"codpy extrapolation: indicators for MNIST\")%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13031f35",
   "metadata": {},
   "source": [
    "Finally, we output as well the confusion matrix for the last scenario in figure \\@ref(fig:585)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da8543d",
   "metadata": {},
   "source": [
    "#### CodPy scores projection\n",
    "\n",
    "In this section we apply straightfowardly the projection operator \\@ref(eq:P), where\n",
    " the training set is $x \\in \\RR^{N_x \\times 784}$, and $y \\in \\RR^{N_y \\times 784} \\subset x$ is randomly chosen. Then we use the projection operator defined in \\@ref(eq:P)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ab89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios.run_scenarios(scenarios_list,MNIST_data_generator_,codpyprClassifier(set_kernel = set_mnist_kernel),data_accumulator(),**codpy_param)\n",
    "results = scenarios.accumulator.get_output_datas().dropna(axis=1).T\n",
    "df_results = pd.concat([df_results,results.T],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0922038d",
   "metadata": {},
   "source": [
    "We output at table \\@ref(tab:595) the list of performance indicators for this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868e30b3",
   "metadata": {
    "label": 595
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results,  caption = \"codpy extrapolation: indicators for MNIST\")%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02502a9",
   "metadata": {},
   "source": [
    "Finally, we output as well the confusion matrix for the last scenario in figure \\@ref(fig:586)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1639cb62",
   "metadata": {},
   "source": [
    "#### Pytorch\n",
    "\n",
    "The Pytorch neural network model is described chapter \\@ref(pytorch-neural-network-model). We use this parameters set to define this Pytorch machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cecdcba",
   "metadata": {
    "echo": true,
    "include": true,
    "show": true
   },
   "outputs": [],
   "source": [
    "torch_param = {'PytorchClassifier': {'epochs': 10,\n",
    "'layers': [128],\n",
    "'batch_size': 16,\n",
    "'loss': nn.CrossEntropyLoss(),\n",
    "'activation': nn.ReLU(),\n",
    "'optimizer': torch.optim.Adam,\n",
    "\"datatype\": \"long\",\n",
    "\"prediction\": \"labeled\",\n",
    "\"out_layer\": 10}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb2af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios.run_scenarios(scenarios_list,MNIST_data_generator_,PytorchClassifier(set_kernel = set_mnist_kernel),data_accumulator(),**codpy_param, **torch_param)\n",
    "results = scenarios.accumulator.get_output_datas().dropna(axis=1).T\n",
    "df_results = pd.concat([df_results,results.T],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eda9ad",
   "metadata": {},
   "source": [
    "We output at table \\@ref(tab:600) the list of performance indicators for this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1700adbe",
   "metadata": {
    "label": 600
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results,  caption = \"Pytorch Neural Network: indicators for MNIST\")%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7981af20",
   "metadata": {},
   "source": [
    "#### Decision Tree\n",
    "\n",
    "The decision tree model is described chapter \\@ref(decision-tree-model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5e3d9b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "scenarios.run_scenarios(scenarios_list,MNIST_data_generator_,DecisionTreeClassifier(set_kernel = set_mnist_kernel),data_accumulator(), **codpy_param)\n",
    "results = scenarios.accumulator.get_output_datas().dropna(axis=1).T\n",
    "df_results = pd.concat([df_results,results.T],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caadb399",
   "metadata": {},
   "source": [
    "We output at table \\@ref(tab:601) the list of performance indicators for this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47060a7",
   "metadata": {
    "label": 601
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results,  caption = \"Decision tree classifier: indicators for MNIST\")%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0b5ee7",
   "metadata": {},
   "source": [
    "#### AdaBoost\n",
    "\n",
    "The Adaboost model is described chapter \\@ref(adaboost-model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e25f6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "scenarios.run_scenarios(scenarios_list,MNIST_data_generator_,AdaBoostClassifier(set_kernel = set_mnist_kernel),data_accumulator(),**codpy_param)\n",
    "results = scenarios.accumulator.get_output_datas().dropna(axis=1).T\n",
    "df_results = pd.concat([df_results,results.T],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035f4745",
   "metadata": {},
   "source": [
    "We output at table \\@ref(tab:602) the list of performance indicators for this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e74da",
   "metadata": {
    "label": 602
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results,  caption = \"AdaBoost classifier: indicators for MNIST\")%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5a1614",
   "metadata": {},
   "source": [
    "#### Gradient Boosting\n",
    "\n",
    "The gradient boosting model is described chapter \\@ref(gradient-boosting-model).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef510645",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "gb_scenarios_list = [ (784, 2**(i), 2**(i-2), 10000)  for i in np.arange(5,10,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e2ee15",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "scenarios.run_scenarios(gb_scenarios_list,MNIST_data_generator_,GradientBoostingClassifier(set_kernel = set_mnist_kernel),data_accumulator(), **codpy_param)\n",
    "results = scenarios.accumulator.get_output_datas().dropna(axis=1).T\n",
    "df_results = pd.concat([df_results,results.T],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdff1a0f",
   "metadata": {},
   "source": [
    "We output at table \\@ref(tab:603) the list of performance indicators for this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc812f8c",
   "metadata": {
    "label": 603,
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results,  caption = \"Gradient Boosting classifier: indicators for MNIST\")%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8bb581",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "\n",
    "The XGBoost model is described chapter \\@ref(xgboost-model). We set its parameters as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5ffe41",
   "metadata": {
    "echo": true,
    "include": true,
    "lines_to_next_cell": 2,
    "show": true
   },
   "outputs": [],
   "source": [
    "xgb_param = {'epochs': 5,\n",
    "'max_depth': 3,\n",
    "'eta' : 0.3,\n",
    "'objective': 'multi:softmax',\n",
    "'num_class': 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9a350a",
   "metadata": {},
   "source": [
    "<!-- ```{python} -->\n",
    "<!-- scenarios.run_scenarios(scenarios_list,MNIST_data_generator_,label_xgboost_predictor(set_kernel = set_mnist_kernel),data_accumulator(), **xgb_param, **codpy_param) -->\n",
    "<!-- results = scenarios.accumulator.get_output_datas().dropna(axis=1).T -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- We output at table \\@ref(tab:604) the list of performance indicators for this test. -->\n",
    "\n",
    "<!-- ```{r, label= 604} -->\n",
    "<!-- knitr::kable(py$results,  caption = \"XGBoost: indicators for MNIST\")%>% -->\n",
    "<!--   kable_styling(latex_options = \"HOLD_position\") -->\n",
    "<!-- ``` -->\n",
    "\n",
    "#### Random Forest\n",
    "\n",
    "The random forest model and its parameter set are described chapter \\@ref(random-forest-model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5902aa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "scenarios.run_scenarios(scenarios_list,MNIST_data_generator_,RandomForestClassifier(set_kernel = set_mnist_kernel),data_accumulator(),**codpy_param)\n",
    "results = scenarios.accumulator.get_output_datas().dropna(axis=1).T\n",
    "df_results = pd.concat([df_results,results.T],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c5a9ab",
   "metadata": {},
   "source": [
    "We output at table \\@ref(tab:605) the list of performance indicators for this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266bc655",
   "metadata": {
    "fig.cap": "performance indicator for Random Forest",
    "label": 605
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results,  caption = \"Random Forest classifier: indicators for MNIST\")%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6789402",
   "metadata": {},
   "source": [
    "#### Support vector classifier\n",
    "\n",
    "The SVC model and its parameter set are described chapter \\@ref(support-vector-classifier-model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1a98fe",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "scenarios.run_scenarios(scenarios_list,MNIST_data_generator_,SVC(set_kernel = set_mnist_kernel),data_accumulator(), **codpy_param)\n",
    "results = scenarios.accumulator.get_output_datas().dropna(axis=1).T\n",
    "df_results = pd.concat([df_results,results.T],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08051bf",
   "metadata": {},
   "source": [
    "We output at table \\@ref(tab:606) the list of performance indicators for this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b25453a",
   "metadata": {
    "fig.cap": "performance indicator for SVC",
    "label": 606,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results,  caption = \"SVC classifier: indicators for MNIST\")%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454feeae",
   "metadata": {
    "fig.cap": "performance indicator for SVC",
    "label": 607
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$df_results,  caption = \"SVC classifier: indicators for MNIST\")%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5761dda4",
   "metadata": {},
   "source": [
    "### Comparing methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ec4a94",
   "metadata": {},
   "source": [
    "The following picture compares methods in term of scores Figure \\@ref(fig:309), discrepancy errors Figure \\@ref(fig:310), and execution time Figure \\@ref(fig:311). We give an interpretation of these results.\n",
    "\n",
    "* First notice that the kernel method *codpy lab extra*, that is the extrapolation method, obtains both best scores and worst execution time. \n",
    "* Notice also that one, minus the dicrepancy error, matches the scores of the method *codpy lab extra*. This indicates that the discrepancy error is a pertinent indicator.\n",
    "* Another kernel method, *codpy lab proj*, that is the projection method above, is a more balanced method [^268].\n",
    "* Both kernel methods are shipped with a very standard kernel, that is the gaussian one, that is the only parameter for kernel methods. We emphasize that Kernel engineering can easily improves these results. We do not present these improved kernel methods, as our purposes is to benchmark standard methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9174d1a",
   "metadata": {},
   "source": [
    "[^268]: except Gradient boosting method, for which we did not succeed retrieving a competitive set of parameters for this test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99d4f06",
   "metadata": {
    "fig.cap": "Benchmark scores",
    "label": 309,
    "results": false
   },
   "outputs": [],
   "source": [
    "scenarios.compare_plots(\n",
    "axis_field_labels = [(\"Nx\",\"scores\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52a3380",
   "metadata": {
    "fig.cap": "Discrepancy errors",
    "label": 310,
    "results": false
   },
   "outputs": [],
   "source": [
    "scenarios.compare_plots(\n",
    "axis_field_labels = [(\"Nx\",\"discrepancy_errors\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968776c1",
   "metadata": {
    "fig.cap": "Benchmarks execution time",
    "label": 311,
    "results": false
   },
   "outputs": [],
   "source": [
    "scenarios.compare_plots(\n",
    "axis_field_labels = [(\"Nx\",\"execution_time\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18534b9",
   "metadata": {},
   "source": [
    "## Reconstruction problems : learning from sub-sampled signals in tomography.\n",
    "\n",
    "This numerical experience illustrates an interesting capability of learning machines to reconstruction problems from sub-sampled signals. Indeed, in this test, we will be learning from a well-established algorithm, that is the SART one, to fasten the reconstruction.\n",
    "\n",
    "There are many applications of such problems. We illustrate this section with a problem coming from a medical image reconstruction, that can be used also as a medical helping diagnosis decision tool. However, such problems occur in a wide variety of other situations: biology, oceanography, astrophysics, ... \n",
    "\n",
    "Poor input signal quality can sometimes be a choice. For instance, in nuclear medicine, it is better to work with lower radioisotopes concentration for obvious health reasons.\n",
    "Another interesting motivation for sub-sampling signals can be also accelerating data acquisition processes from expensive machines. \n",
    "\n",
    "We illustrate this section with an example of such a reconstruction coming from reconstructing a signal from a sub-sampled SPEC (tomography) problem that we describe now. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89344662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preamble import *\n",
    "plt.close('all')\n",
    "from radon import *\n",
    "codpy_param = {'rescale:xmax': 1000,\n",
    "'rescale:seed':42,\n",
    "'sharp_discrepancy:xmax':1000,\n",
    "'sharp_discrepancy:seed':30,\n",
    "'sharp_discrepancy:itermax':5,\n",
    "'discrepancy:xmax':500,\n",
    "'discrepancy:ymax':500,\n",
    "'discrepancy:zmax':500,\n",
    "'discrepancy:nmax':2000,\n",
    "'validator_compute': ['accuracy_score']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934b77f4",
   "metadata": {},
   "source": [
    "### A problem coming from SPECT tomography\n",
    "\n",
    "The purpose of this test is to illustrate a sub-sampling reconstruction in the context of medical imagery, more precisely from sub-sampled SPECT images. To that aim, we start from collecting a set of *high resolution* images[^594]. The set itself  is not really important for our illustration sake in this section. However it  should be chosen carefully for real, production problem.\n",
    "\n",
    "[^594]: the image set is available publicly at this [kaggle link](https://www.kaggle.com/vbookshelf/computed-tomography-ct-images/). \n",
    "\n",
    "This database image consists in high resolution (512x512) images, consisting in approximately 30 images of 82 patients. The training set is built on the first 81 patient. The 82-th patient is used for the test set. We first transform the training set database to produce our data. For each image in the training set (2470 images):\n",
    "\n",
    "* We perform a \"high\" resolution (256x256) radon transform [^357], called a **sinogram** [^324]. A sinogram is quite close to a Fourier transform of the original image, generating sinusoids.\n",
    "* We perform a \"low\" resolution (8x256) radon transform.\n",
    "* We reconstruct the original image from the high resolution sinogram to simulate high resolution SPECT images from these data. The reconstruction algorithm consists in computing an inverse radon transform [^424]. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b0eb59",
   "metadata": {},
   "source": [
    "An example of training set construction is presented Figure \\ref{fig:SPECT}. Left is the reconstructed image from the \"high resolution\" sinogram (middle). The low resolution sinogram is plot at right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d920cf73",
   "metadata": {
    "fig.align": "center",
    "fig.cap": "high resolution sinogram (middle),  low resolution (right), reconstructed image (left)",
    "label": "#R_CODE#SPECT",
    "out.width": "90%"
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::include_graphics(path = \"./CodPyFigs/SPECT.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd8e247",
   "metadata": {},
   "source": [
    "[^357]: An introduction to radon transform can be found at [ this wikipedia page](https://en.wikipedia.org/wiki/Radon_transform).\n",
    "\n",
    "[^324]: We used the standard radon transform from scikit, [available at this url](https://scikit-image.org/docs/dev/api/skimage.transform.html#skimage.transform.radon).\n",
    "\n",
    "[^424]: We used a SART algorithm, 3 iterations, for reconstruction, [available at this url](https://scikit-image.org/docs/dev/api/skimage.transform.html#skimage.transform.iradon_sart).\n",
    "\n",
    "The test consists then in reconstructing all images of the 82-th patient using low-resolution sinograms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba00cc8",
   "metadata": {},
   "source": [
    "### Performing the test\n",
    "\n",
    "We present here the test resulting from a benchmark of a kernel-based method and the SART algorithm[^269]\n",
    "\n",
    "[^269]: We did not succeed finding competitive parameters for other methods.\n",
    "\n",
    "Following our notations, section  \\@ref(notation-and-setup), we introduce\n",
    "\n",
    "* The training set $x \\in \\RR^{2473 \\times 2304}$, consisting in 2473 sinograms having resolution $8 \\times 256$, consisting in all low-resolution sinograms of the 81 first patients, plus the first one of the 82-th patient. This last figure is added to check an important feature in these problems : the learning machine must be able to retrieve an already input example.\n",
    "* The test set $z \\in \\RR^{29 \\times 2304}$, consisting in 29 sinograms of the 82-th patient, having resolution $8 \\times 256$.\n",
    "* The training values set $f_x \\in \\RR^{2473 \\times 65536}$, consisting in the 2473 images in \"high-resolution\".\n",
    "* The ground truth values $f(z) \\in \\RR^{29 \\times 65536}$, consists in 29 images in \"high-resolution\".\n",
    "\n",
    "We perform the tests and output the results in Table \\ref{tab:207}. The columns are the predictor identifiant, $D,N_x,N_y,N_z,D_f$, the execution time, and the score, computed with the RMSE \\% error indicator, see \\@ref(eq:rmse).\n",
    "\n",
    "* The first line, named *exact*, simply output the original figures, leading to zero error.\n",
    "* The second one, named *SART*, reconstruct the figures from the SART algorithm with sub-sampled data.\n",
    "* The third one, named *codpy*, reconstruct the figures from the sub-sampled data with the kernel extrapolation method \\@ref(eq:EI)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcbc9ac",
   "metadata": {},
   "source": [
    "The figure \\@ref(fig:359) plots the first 8 images, presenting the original one at left, the reconstruction from SART algorithm, middle, and our algorithm, right. One can check visually that this kernel method better reconstruct the original image. It would be erroneous to conclude that this reconstruction process performs better than the SART algorithm, and it is not at all our speech here. We simply illustrate here the capacity of our algorithm to recognize existing patterns: indeed, note that the first image is perfectly reconstructed, as it is part of the training set. This property emphasizes that such methods suit well to pattern recognition problems, as automated tools to support professionals diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12af8fc0",
   "metadata": {
    "fig.align": "center",
    "fig.cap": "Example of reconstruction original (left), sub-sampled SART (middle), kernel extrapolation (right)",
    "label": 359,
    "lines_to_next_cell": 2,
    "out.width": "50%"
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::include_graphics(here::here(\"CodPyFigs\", \"reconstruction.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497071a4",
   "metadata": {
    "lines_to_next_cell": 0,
    "results": false
   },
   "outputs": [],
   "source": [
    "## remote execute file radon.py,as execution time is too long."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8435e5df",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "label,code,include,results,out.width,fig.cap,fig.align,echo,tags,show,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
