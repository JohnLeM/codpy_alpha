{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0ef6fc15",
   "metadata": {},
   "source": [
    "---\n",
    "output:\n",
    "  pdf_document:\n",
    "    keep_tex: yes\n",
    "    includes:\n",
    "      in_header: preamble.tex\n",
    "  html_document: default\n",
    "  word_document: default\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962c3432",
   "metadata": {
    "name": "setup",
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "for_pdf <- TRUE\n",
    "for_html <- FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f10869",
   "metadata": {
    "code": "#R_CODE#xfun::read_utf8('preamble.R')",
    "lines_to_next_cell": 2,
    "tags": [
     "remove_cell",
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "%%R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607bc519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preamble import *\n",
    "plt.close('all')\n",
    "codpy_param = {'rescale:xmax': 1000,\n",
    "'rescale:seed':42,\n",
    "'sharp_discrepancy:xmax':1000,\n",
    "'sharp_discrepancy:seed':30,\n",
    "'sharp_discrepancy:itermax':5,\n",
    "'discrepancy:xmax':500,\n",
    "'discrepancy:ymax':500,\n",
    "'discrepancy:zmax':500,\n",
    "'discrepancy:nmax':2000}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff368e3",
   "metadata": {},
   "source": [
    "# Brief overview of methods of machine learning\n",
    "\n",
    "<!-- \\fancyhead[CO,CE]{Your Document Header} -->\n",
    "\n",
    "## A framework for machine learning \n",
    "\n",
    "### Prediction machine for supervised/unsupervised machine learning\n",
    "\n",
    "Machine learning methods can be roughly split into two main approaches: unsupervised and supervised methods. Both can be described in a general framework, referred to here as a **prediction machine**. In short, a predictor, denoted by $\\mathcal{P}_m$, is an extrapolation or interpolation procedure, described by an operator \n",
    "\\begin{equation} \n",
    "  f_z = \\mathcal{P}_{m}(x,y=[],z=x,f(x)=[]).\n",
    "  (\\#eq:Pm)\n",
    "\\end{equation}\n",
    "Python notation is used here and the brakets mean that the variables $y, z, f(x)$ are optional input data.\n",
    "\n",
    "* The choice of the method is indicated by the subscript $m$. Each method relies on a set of **external parameters**. Fine tuning such parameters is sometimes very cumbersome and provide a source of error and, in fact, some of the strategies in the literature propose to rely on a learning machine in order to determine these external parameters. No performance indicator is provided for this parameter tuning step, and this is an issue to take into account in the applications before selecting up a particular method.\n",
    "\n",
    "* The input data $x, y, z, f(x)$ are as follows. \n",
    "  * The only non-optional parameter is the variable $x \\in \\mathbb{R}^{N_x \\times D}$, called the **training set**. The parameter $D$ is usually referred as the **total number of features**.\n",
    "  * The variable $f(x) \\in \\mathbb{R}^{N_x \\times D_f}$ is called the **training set values**, whilethe parameter $D_f$ is the **number of training features**.\n",
    "  * The variable $z \\in \\mathbb{R}^{N_z \\times D}$ is called the **test set**. If it is not specified, we tacitly assume that $z=x$.\n",
    "  * The variable $y \\in \\mathbb{R}^{N_y \\times D}$ is called the **internal parameter set**\\footnote{also called weight set in neural network theory} and is necessary in order to define $\\mathcal{P}_m$.\n",
    "* The output data are as follow: \n",
    "  * **Supervised learning**: this corresponds to choosing the input function values $f(x)$ and we then write \n",
    "$$  \n",
    "f_z = \\mathcal{P}_m(x,y=[],z=x,f(x)), (\\#eq:Pms)\n",
    "$$\n",
    "  where the values $f_z \\in \\RR^{N_z \\times D}$ are called a **prediction**.\n",
    "We distinguish between two cases:\n",
    "    * If the input data $y$ is left empty, then the prediction machine \\@ref(eq:Pm) is called a **feed-backward machine**. In this case, the method computes this set with an internal method and determine $f_z$.\n",
    "    * If $y$ is specified as input data, then the prediction machine \\@ref(eq:Pm) is referred as a **feed-forward machine**. In this case, the method uses the set of internal parameters and compute the prediction $f_z$.\n",
    "  * **Unsupervised learning**: we may also choose \n",
    "\\begin{equation} \n",
    "  f_z = \\mathcal{P}_m(x,z=x), (\\#eq:Pmu)\n",
    "\\end{equation}\n",
    "where the output values $f_z \\in \\mathbb{R}^{N_z \\times D}$ are sometimes called **clusters** for the so-called clustering methods (described later on).\n",
    "  \n",
    "Other machine learning methods can be described with the same notation. For instance, two methods $m_1,m_2$ begin given, then the following composition describes a feed-backward machine, which is quite close to the definition of **semi-supervised learning** in the literature and also encompasses feed-backward learning machines: \n",
    "$$ \n",
    "  f_z = \\mathcal{P}_{m_1}(x, \\mathcal{P}_{m_2}(x,f(x)),z,f(x)), (\\#eq:Pmsu)\n",
    "$$\n",
    "We summarize our main notation in Table \\@ref(tab:mainnotations). The sizes of the input data, that is, the integers $D, N_x, N_y, N_z, D_f$, are also considered as input parameters. The distinction between supervised and unsupervised learning is a matter of having, or not, optional input data and the correspondence will be clarified in the rest of this chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e616178",
   "metadata": {
    "eval": "#R_CODE#for_html",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "summary = data.frame(\n",
    "  stringsAsFactors = FALSE,\n",
    "       check.names = FALSE,\n",
    "                 x = c(\"training set\",\"size Nx * D\"),\n",
    "                 y = c(\"parameter set\",\"size Ny * D\"),\n",
    "                 z = c(\"test set\",\"size Nz * D\"),\n",
    "            `f(x)` = c(\"training values\",\"size Nx * Df\"),\n",
    "           `fz` = c(\"predictions\", \"size Nz * Df\")\n",
    ")\n",
    "knitr::kable(summary, label = \"mainnotations\", caption = \"Main parameters for machine learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8876c5",
   "metadata": {},
   "source": [
    "| $x$           |  $y$           | $z$       |          $f(x)$  |        $f_z$ |\n",
    "|---            |          ---   |---        |---      |---     |\n",
    "| training set  | parameter set  |  test set | training values  | predictions  |\n",
    "| size $N_x \\times D$ | size   $N_y \\times D$       |  size $N_z \\times D$    |      size $N_x \\times Df$       |     size $N_z \\times Df$     |\n",
    "\n",
    "Table:  (\\#tab:mainnotations) Main parameters for machine learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a962822a",
   "metadata": {},
   "source": [
    "### Techniques of supervised learning \n",
    "\n",
    "Supervised learning \\@ref(eq:Pms) corresponds to the case where the function values $f(x)$ is part of input data. \n",
    "\\begin{equation} \n",
    "  f_z = \\mathcal{P}_m(x,y=[],z=x,f(x)).\n",
    "\\end{equation}\n",
    "Supervised learning can be best understood as a simple extrapolation procedure: from historical observations of a given function $x, f(x)$, one wants to predict, or extrapolate, the function on a new set of values $z$.\n",
    "Concerning the terminology, a method is said to be **multi-class** or multi-output if the function $f$ under consideration can be vector-valued, that is, $D_f \\ge 1$ with our notations. Note that one can always stack learning machines to produce multi-class methods. However, this comes usually at a quite heavy computational cost, motivating this definition. Moreover, the input function $f$ can be\n",
    "\n",
    "* discrete, that is the set of unique values $f(\\RR^D)$ is a discrete set, denoted $Ran(f)$. The set is referred as **labels**, and this set can always be mapped to integer $[1,\\ldots,\\#(Ran(f))]$, where $\\#(E)$ denotes the number of elements, or cardinal, of a set.\n",
    "* continuous.\n",
    "* mixed (some discrete, some continuous).\n",
    "\n",
    "A classification of existing methods for supervised learning can be found at scikit-learn \n",
    "\n",
    "[^200]:[a classification of methods is available using this link]\n",
    "(https://scikit-learn.org/stable/supervised_learning.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b5f244",
   "metadata": {},
   "source": [
    "There are\n",
    "\n",
    "* Different family of methods: linear models, support vector machines, neural networks, …\n",
    "\n",
    "![](.\\CodPyFigs\\SMLT.png){width=50%}\n",
    "\n",
    "* Different methods: neural networks, gaussian processes, etc...\n",
    "\n",
    "![](.\\CodPyFigs\\SML.png){width=50%}\n",
    "\n",
    "* Different libraries: scikit-learn, Tensorflow, ...\n",
    "\n",
    "### Techniques of unsupervised learning \n",
    "\n",
    "Unsupervised learning corresponds to the case where the function values $f(x)$ is not part of input data, see \\@ref(eq:Pms) :\n",
    "\\begin{equation} \n",
    "   \\mathcal{P}_m(x, y = [] , z = x). \n",
    "\\end{equation}\n",
    "Unsupervised learning can be best understood as a simple interpolation procedure: from historical observations of a given distribution $x$, one wants to extract, or interpolate, $N_y$ features that best represent $x$.\n",
    "The output data of a standard clustering method are the **cluster set**, denoted $y \\in \\mathbb{R}^{N_y\\times D}$.\n",
    "\n",
    "There are natural connections between supervised and unsupervised learning.\n",
    "\n",
    "* In the context of semi-supervised clustering methods, the clusters $y$ are used in a supervised learning machine to produce a prediction $f_z \\in\\mathbb{R}^{N_z \\times D_f}$, see \\@ref(eq:Pmsu).\n",
    "* In the context of unsupervised clustering methods, a prediction $f_z \\in\\mathbb{R}^{N_z}$ can also be made. This prediction attaches each point $z^i$ of the test set to the cluster set $y$, producing $f_z$ as a map $[1,\\ldots,N_z] \\mapsto [1,\\ldots,N_y]$.\n",
    "\n",
    "There exists several clustering methods performing this approach, see for instance the dedicated Wikipedia page[^202].\n",
    "\n",
    "[^202]:[link to cluster analysis Wikipedia page](https://en.wikipedia.org/wiki/Cluster_analysis). \n",
    "\n",
    "* Different family of methods: linear models, support vector machines, neural networks,...\n",
    "\n",
    "![](.\\CodPyFigs\\UMLT.png){width=50%}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d851b65",
   "metadata": {},
   "source": [
    "* Different methods: neural networks, Gaussian processes, etc..\n",
    "\n",
    "![](.\\CodPyFigs\\UML.png){width=50%}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dba57ba",
   "metadata": {},
   "source": [
    "* Different libraries: Scikit-learn, ...\n",
    "\n",
    "Clustering is one family of unsupervised learning method. The library Scikit-learn proposes this quite impressive list of clustering methods, see [^203]. We extracted the following figure and comment it briefly to illustrate our notation.\n",
    "\n",
    "[^203]:[link to scikit-learn clustering](https://scikit-learn.org/stable/modules/clustering.html)\n",
    "\n",
    "![list of scikit-learn clustering methods.](CodPyFigs/scikitclustercomparaison.png)\n",
    "\n",
    "* Each column describes a particular clustering algorithm.\n",
    "* Each row describes a particular clustering, unsupervised problem:\n",
    "  * Each image scatter plots the training set $x$ and the test set $z$, that are equals.\n",
    "  * Each image color codes the predicted values $f_z$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aaa3f1",
   "metadata": {},
   "source": [
    "## Exploratory data analysis\n",
    "\n",
    "### Preliminaries\n",
    "Exploratory data analysis plays a central role in data engineering and allows one to understand the structure of a given dataset, including its correlation and statistical properties. For instance, we can study whether a data distribution is multi-modal, skew, or discontinuous, among other features. The technique can help in many different applications and, for instance in unsupervised learning, one can produce a first guess concerning the number of possible clusters associated with a given dataset, or concerning the type of kernels one should choose before applying a kernel regression method.\n",
    "\n",
    "As an example, we illustrate the visualization tools that we are using, consider the Iris flower data set. Iris data set introduced by the British statistician, eugenicist, and biologist Ronald Fisher in his 1936 paper \"The use of multiple measurements in taxonomic problems\". The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.\n",
    "\n",
    "### Visualization based on non-parametric estimations\n",
    "The density of the input data is estimated using a kernel density estimate (KDE). Let $(x^1, x^2, \\dots, x^n)$ be independent and identically distributed samples, drawn from some univariate distribution with unknown density denoted by $f$ at any given point $x$. We are interested in estimating the shape of this function $f$ and the kernel density estimator is\n",
    "$$\n",
    "\\widehat{f}_{h}(x)={\\frac {1}{n}}\\sum _{i=1}^{n}K_{h}(x-x^{i})={\\frac {1}{nh}}\\sum _{i=1}^{n}K{\\Big (}{\\frac {x-x^{i}}{h}}{\\Big )},\n",
    "$$\n",
    "where $K$ is a kernel (say any non-negative function) and $h > 0$ is a smoothing parameter called the **bandwidth**. Among the range of possible kernels that are are commonly used, we have: uniform, triangular, biweight, triweight, Epanechnikov, normal, and many others. The ability of the KDE to accurately represent the data depends on the choice of the smoothing bandwidth. An over-smoothed estimate can remove meaningful features, but an under-smoothed estimate can obscure the true shape within the random noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f062f",
   "metadata": {
    "fig.cap": "Kernel density estimator",
    "label": "#R_CODE#0001",
    "lines_to_next_cell": 2,
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "D,Nx,Ny,Nz= -1,-1,-1,-1\n",
    "x, fx, y, fy, z, fz = iris_data_generator().get_data(D = D,Nx= Nx, Ny = Ny, Nz = Nz)\n",
    "f_names = iris_data_generator().get_feature_names()\n",
    "xfx = pd.DataFrame(x, index = np.reshape(fx,(len(fx))), columns = f_names)\n",
    "multi_plot([xfx.T],data_plots.distribution_plot1D, f_names = f_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10c40c1",
   "metadata": {},
   "source": [
    "### Visualization based on scatter plots\n",
    "\n",
    "Another way to visualize data is to rely on a scatter plot, where the data are displayed as a collection of points, each having the value of one variable determining the position on the horizontal axis and the value of the other variable determining the position on the vertical axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff65a7c5",
   "metadata": {
    "fig.cap": "Scatter plot",
    "label": "#R_CODE#0002",
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "multi_plot(x.T,data_plots.scatter_plot, f_names = f_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53040d1",
   "metadata": {},
   "source": [
    "### Visualization based on correlation matrices\n",
    "\n",
    "The correlation matrix of $n$ random variables $x^{1},\\ldots ,x^{n}$ is the $n\\times n$ matrix whose $(i,j)$ entry is $corr(x^{i},x^{j})$. Thus the diagonal entries are all identically unity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a11bb7a",
   "metadata": {
    "fig.cap": "Correlation matrix",
    "label": "#R_CODE#0003",
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "data_plots.heatmap(x, title= \"Correlation matrix\", f_names = f_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e07f0de",
   "metadata": {},
   "source": [
    "### Visualization based on summary plots\n",
    "\n",
    "The summary plot visualizes the density of each feature of the data on the diagonal. The KDE plot on the lower diagonal and the scatter plot on the upper diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc62b9e",
   "metadata": {
    "fig.cap": "Summary plot",
    "label": "#R_CODE#00019",
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "data_plots.density_scatter(xfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4128218",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "scenarios_list = [ (784, 2**(5), 2**(5-2), 10000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fddb17",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a59f645",
   "metadata": {},
   "source": [
    "## Performance indicators for machine learning\n",
    "\n",
    "### Indicators for supervised learning\n",
    "\n",
    "**Comparison to ground truth values**. A huge family of indicators is available in order to evaluate the performance of a learning machine, most of them being readily described and implemented in scikit-learn[^204]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a8aae8",
   "metadata": {},
   "source": [
    "[^204]:[link to scikit-learn metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics). \n",
    "\n",
    "We do not discuss them all, but rather overview those that we have included in the CodPy library. First of all, in the context of supervised clustering methods, if the function $f$ is known in advance, then predictions of learning machines $f_z$ can be compared with **ground truth values**, $f(z) \\in \\mathbb{R}^{N_z \\times D_f}$. Below we list the main metrics that are used.\n",
    "\n",
    "* For labeled functions (i.e., discrete functions), a common indicator is the **score**, defined as\n",
    "$$\n",
    "    \\frac{1}{N_z} \\#\\{ f_z^n = f(z)^n, n=1\\ldots N_z\\} (\\#eq:score)\n",
    "$$\n",
    "producing an indicator between 0 and 1, the higher being the better.\n",
    "* For continuous functions (i.e., discrete functions), a common indicator is $\\ell^p$ norms, defined as\n",
    "$$\n",
    "    \\frac{1}{N_z}\\| f_z - f(z) \\|_{\\ell^p}, \\ 1 \\le p \\le \\infty. \n",
    "$$\n",
    "the case $p=2$ is referred as the *root-mean-square error (RMSE)*. \n",
    "\n",
    "* As the above indicator is not normalized, the following version is preferred.\n",
    "$$\n",
    "    \\frac{\\| f_z - f(z)\\|_{\\ell^p}}{\\| f_z\\|_{\\ell^p} +\\|f(z)\\|_{\\ell^p}}, \\ 1 \\le p \\le \\infty. (\\#eq:rmse)\n",
    "$$\n",
    "producing an indicator between 0 and 1, the smaller being the better, interpreted as error-percentages.\n",
    "In finance, this notion is sometimes referred to as the basis point indicator.\n",
    "\n",
    "**Cross validation scores**. The cross validation score consists in randomly selecting a part of the training set and values as test set and values, and to perform a score or RMSE type error analysis on each run[^205]\n",
    "\n",
    "**Confusion matrix**. This indicator is available for labeled, supervised learning, is a matrix representation of the numbers of ground-truth labels in a row, while each column represents the predicted labels in an actual class. Confusion matrix is a quite simple and efficient data error visualization methods, a simple example is shown in Section \\@ref(k-means-confusion-matrix). Its common form is\n",
    "$$\n",
    "  M(i,j) = \\#\\{f(z) = i \\quad and \\quad f_z = j\\},\n",
    "$$\n",
    "representing correct predicted numbers in the matrix diagonal, since off-diagonal elements counts false positive predictions. Note that numerous others performance indicators can be straightforwardly deduced from the confusion matrix, as Rand Index, Fowlkes-Mallows scores, etc...\n",
    "\n",
    "**Norm of output**. If no ground truth values are known, the quality of the prediction $f_z$, depends on **a priori error estimates** or error bounds. Such estimates exist only for kernel methods (to the best of the knowledge of the authors), and are described in the next chapter, see \\@ref(eq:err). Such estimates uses the norm of functions described in \\@ref(eq:norm), and was proven to be a useful indicator in the applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d116c55",
   "metadata": {},
   "source": [
    "[^205]:see the [dedicated page on scikit-learn](https://scikit-learn.org/stable/modules/cross_validation.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb45a01",
   "metadata": {},
   "source": [
    "**ROC curves**. A receiver operating characteristic curve, or ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The method was originally developed for operators of military radar receivers starting in 1941, which led to its name.\n",
    "\n",
    "ROC is the plot of TPR versus FPR by varying the threshold. These metrics are are summed up in the table below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f66b543",
   "metadata": {},
   "source": [
    "| Metric   |      Formula |  Equivalent |\n",
    "|----------|:-------------:|------:|\n",
    "| True Positive Rate TPR |  $\\frac{TP}{TP + FN}$ | Recall, sensitivity |\n",
    "| False Positive Rate FPR|    $\\frac{FP}{TN+FP}$  |   \t1-specificity |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6c4b5f",
   "metadata": {},
   "source": [
    "We can use precision score ($PRE$) to measure the performance across all classes:\n",
    "\n",
    "$$\n",
    "PRE=\\frac{TP}{TP+FP}.\n",
    "$$\n",
    "In “micro averaging”, we calculate the performance, e.g., precision, from the individual true positives, true negatives, false positives, and false negatives of the the k-class model:\n",
    "$$\n",
    "PRE_{micro}=\\frac{TP_{1}+\\dots+TP_{k}}\n",
    "{TP_{1}+\\dots+TP_{k}+FP_{1}+\\dots+FP_{k}}.\n",
    "$$\n",
    "And in macro-averaging, we average the performances of each individual class\n",
    "$$\n",
    "PRE_{marco}=\\frac{PRE_{1}+\\dots+PRE_{k}}{k}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641dc97a",
   "metadata": {},
   "source": [
    "### Indicators for unsupervised learning\n",
    "\n",
    "**Discrepancy error associated to kernel**. Evaluation of clustering algorithms benefits from a lot of performance indicators, a lot of them being implemented in Scikit-learn [^206]\n",
    "[^206]:[see this link](https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b21589",
   "metadata": {},
   "source": [
    "We list in this section those that we are computing. First of all, the discrepancy error is an indicator based on a kernel and will be fully described in the next chapter, see \\@ref(eq:dk). It is used primarily to produce worst error estimates, together with the norm of functions, as described in \\@ref(eq:norm). It was also found to be useful as a performance indicator for unsupervised learning machine.\n",
    "\n",
    "**Inertia indicator**. The inertia indicator is used for *k-means* type algorithms. We describe it precisely, as it uses a notation that will be used in other parts. It shares some similarities with the discrepancy error one but is not equivalent. \n",
    "To define inertia, one first pick a distance, denoted $d(x, y)$, as the squared Euclidean one, although other distance are considered, as the Manhattan one or log-entropy, depending upon the problem under consideration. Consider now any point $w \\in \\RR^D$. Then $w$ is attached naturally to a point $y^{\\sigma_d(w,y)}$, where the discrete function $\\sigma_d(w,y)$ is computed as \n",
    "$$\n",
    "\\sigma_d(w,y) := \\{ j : d(w,y^j) = \\inf_k d(w,y^k) \\}. (\\#eq:sigmaw)\n",
    "$$\n",
    "Then the inertia is defined as\n",
    "$$\n",
    "I(x,y)= \\sum_{n=0}^{N_x} ( |x^n-y^{\\sigma_{d}(x^n,y)}|^2).\n",
    "$$\n",
    "Observe that this functional might not be convex, even if the distance under consideration is convex, as is the squared Euclidean distance. For k-means algorithms, the cluster centers $y$ are computed minimizing this functional. The parameter set $y$ is called **centroids** for k-means algorithms. \n",
    "\n",
    "**Homogeneity score**. The homogeneity score, see the dedicated scikit-learn for a definition [^492], is a performance indicator that holds for supervised, labeled, clustering problems. This indicator performs a conditional entropy to estimate a score $s(f(z), f_z)$ between 0 and 1 - higher the better.\n",
    "[^492]:[see this link](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.homogeneity_score.html#sklearn.metrics.homogeneity_score) \n",
    "\n",
    "**Silhouette coefficient**. If the ground truth labels are not known, evaluation must be performed using the model itself. The [Silhouette Coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score) is an example of such an evaluation, where a higher Silhouette Coefficient score relates to a model with better defined clusters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d706c0fb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## General specification of tests\n",
    "\n",
    "### Preliminaries \n",
    "\n",
    "We now overview a benchmark methodology and apply it to a few methods of supervised learning. For each machine, \n",
    "* we illustrate the prediction function $\\mathcal{P}_m$, and \n",
    "* we illustrate the computation of some performance indicators.\n",
    "We then present benchmarks using these indicators. In this section, we restrict attention to toy examples while more significant examples will be studied in Chapter \\@ref(application-to-supervised-machine-learning).\n",
    "\n",
    "We begin by describing a general, multi-dimensional, first quality assurance test for supervised learning machines. We illustrate this test framework with one and two-dimensional examples, and the reader can toy with functions and methods.\n",
    "The goal of this framework is to measure accuracy of any learning machines, while using the extrapolation operator (\\#eq:EI). Hence all our unit tests are based on the following input sizes:\n",
    "$$\n",
    "  \\text{a function: f },\\text{a method: m }, \\text{five integers: } D, N_x, N_y, N_z, D_f\n",
    "$$\n",
    "To benchmark our machine, we use a list of scenarios, that is a list of entries $D, N_x, N_y, N_z, D_f$. Table \\@ref(tab:299) is an example of a list of 5 scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09b419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_list = [ (1, 100*i, 100*i ,100*i ) for i in np.arange(1,5,1)]\n",
    "pd_scenarios_list = pd.DataFrame(scenarios_list,columns = [\"D\",\"Nx\",\"Ny\",\"Nz\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc5f9ec",
   "metadata": {
    "label": 299,
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$pd_scenarios_list, caption = \"scenario list\", col.names = c(\"$D$\",\"$N_x$\",\"$N_y$\",\"$N_z$\"), escape = FALSE)%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4340a4c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "For the function $f$ we choose a period and an increasing function:\n",
    "\\begin{equation} \\label{2D}\n",
    "f(x) = \\Pi_{d=1..D} \\cos (4\\pi x_d) + \\sum_{d=1..D} x_d.\n",
    "\\end{equation}\n",
    "It is defined in python code of this document, and the reader can change it to any other continuous function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae8d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_fun(x):\n",
    "    import numpy as np\n",
    "    from math import pi\n",
    "    D = len(x)\n",
    "    res = 1.;\n",
    "    for d in range(0,D):\n",
    "        res *= np.cos(4 * x[d] * pi) \n",
    "    for d in range(0,D):\n",
    "        res += x[d]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28cf330",
   "metadata": {},
   "source": [
    "### An example in one dimension\n",
    "\n",
    "**Initialization**. For this tutorial, we used a generator, configured to select $x$ (resp. $y, z$) as $N_x$ (resp. $N_y, N_z$) points regularly (resp. randomly, regularly) generated on a unit cube. We chose to select $z$ distributed over a larger cube, to observe extrapolation and interpolation effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045bc127",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_random_generator_ = data_random_generator(fun = my_fun,types=[\"cart\",\"sto\",\"cart\"])\n",
    "x, fx, y, fy, z, fz =  data_random_generator_.get_data(D=1,Nx=100,Ny=100,Nz=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7bf978",
   "metadata": {},
   "source": [
    "As an illustration, in Figure \\@ref(fig:xfxzfz) we show both graphs $(x, f(x))$ (left, training set),$(z, f(z))$ (right, test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab73be0",
   "metadata": {
    "fig.cap": "training and test set.",
    "label": "#R_CODE#xfxzfz"
   },
   "outputs": [],
   "source": [
    "multi_plot([(x, fx),(z, fz)],plot1D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0e5c88",
   "metadata": {},
   "source": [
    "## Benchmark methodology:  kernel-based predictors\n",
    "\n",
    "### Periodic kernel regression model from CodPy\n",
    "\n",
    "This test illustrates a kernel-based projection operator, described in Section \\@ref(fundamental-notions-for-supervised-learning). The set of external parameters for kernel-based methods consists simply in picking-up a kernel, and is discussed in the next chapter; see Section \\@ref(kernel-methods-for-machine-learning). We pick-up in the corresponding python chunk a standard periodic Gaussian kernel, with a linear regression kernel, allowing us to fit both periodic and polynomial parts of these data. These settings are explained in Chapter \\@ref(dealing-with-kernels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ee9cf2",
   "metadata": {
    "echo": true,
    "include": true,
    "show": true
   },
   "outputs": [],
   "source": [
    "set_per_kernel = kernel_setters.kernel_helper(kernel_setters.set_gaussianper_kernel,2,1e-8,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b59879c",
   "metadata": {},
   "source": [
    "We then run all the scenarios in Section \\@ref(tab:299)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595232a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_generator_ = scenario_generator()\n",
    "scenario_generator_.run_scenarios(scenarios_list,data_random_generator_,\n",
    "codpyexRegressor(set_kernel = set_per_kernel),\n",
    "data_accumulator(), **codpy_param)\n",
    "results = scenario_generator_.accumulator.get_output_datas().dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db897816",
   "metadata": {},
   "source": [
    "We plot the first two results of this test in Figure \\@ref(fig:xfxzfzper) : predictions, denoted $f_z$ of the function $f(z)$, see Figure \\@ref(fig:xfxzfz), for the first two scenarios defined in Section \\@ref(tab:299)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb370b21",
   "metadata": {
    "fig.cap": "periodical kernel : two predictions.",
    "label": "#R_CODE#xfxzfzper"
   },
   "outputs": [],
   "source": [
    "list_results = [(s.z,s.f_z) for s in scenario_generator_.accumulator.predictors]\n",
    "multi_plot(list_results,plot1D,mp_max_items = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b29d49e",
   "metadata": {},
   "source": [
    "Table \\@ref(tab:654) shows the computed indicators during this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc59db6e",
   "metadata": {
    "label": 654
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results,  caption = \"CodPy performance indicators\", col.names = c(\"$predictor_{id}$\", \"$D$\", \"$N_x$\", \"$N_y$\", \"$N_z$\", \"$D_f$\", \"time\", \"scores\", \"norm function\", \"discr.error\"), escape = FALSE)%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5865b20f",
   "metadata": {},
   "source": [
    "### The kernel regression model from SciPy\n",
    "\n",
    "Scipy proposes a solid and robust kernel regression predictor, see [this link](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.Rbf.html). We often benchmark our kernel implementation with it. Let us first set up the external parameters for Scipy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d583f773",
   "metadata": {
    "echo": true,
    "include": true,
    "show": true
   },
   "outputs": [],
   "source": [
    "rbf_param = {'function': 'gaussian', 'epsilon':None, 'smooth':1e-8, 'norm':'euclidean'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c632ca96",
   "metadata": {},
   "source": [
    "Indeed, we now proceed by copy-pasting the previous section, to highlight that benchmark methodologies should be method-independent. We then run our scenario list and collect results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3eb71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_generator_.run_scenarios(scenarios_list,data_random_generator_,\n",
    "ScipyRegressor(set_kernel = set_per_kernel),\n",
    "data_accumulator(), **codpy_param)\n",
    "results = scenario_generator_.accumulator.get_output_datas().dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c41c5f",
   "metadata": {},
   "source": [
    "We plot the two first results in Figure \\@ref(fig:xfxzfzscipy) : these are the predictions, denoted $f_z$, of the function $f(z)$; see Figure \\@ref(fig:xfxzfz), for the first two scenarios defined in Section \\@ref(tab:299)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238523b5",
   "metadata": {
    "fig.cap": "scipy : two predictions.",
    "label": "#R_CODE#xfxzfzscipy"
   },
   "outputs": [],
   "source": [
    "list_results = [(s.z,s.f_z) for s in scenario_generator_.accumulator.predictors]\n",
    "multi_plot(list_results,plot1D,mp_max_items = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0f6e89",
   "metadata": {},
   "source": [
    "Table \\@ref(tab:568) shows the computed indicators after running all scenarios indicated in the Table  \\@ref(tab:299)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477a8cb2",
   "metadata": {
    "fig.cap": "indicator for scipy method.",
    "label": 568
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results,  caption = \"scipy performance indicators\", col.names = c(\"$predictor_{id}$\", \"$D$\", \"$N_x$\", \"$N_y$\", \"$N_z$\", \"$D_f$\", \"time\", \"scores\", \"norm function\", \"discr.error\"), escape = FALSE)%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aec1a66",
   "metadata": {},
   "source": [
    "### Support vector regression model\n",
    "\n",
    "For this test, the interpolation machine is chosen to be a support vector classifier, taken from scikit learn. It specified by a decision function (support vector classifier) and the kernel function associated to it, see [this dedicated page for a description of SVC](https://scikit-learn.org/stable/modules/svm.html). The reader can tune this set of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7325fa",
   "metadata": {
    "echo": true,
    "include": true,
    "show": true
   },
   "outputs": [],
   "source": [
    "svm_param = {'kernel': 'linear', 'gamma': 'auto', 'C': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db241e8f",
   "metadata": {
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "scenario_generator_.run_scenarios(scenarios_list,\n",
    "data_random_generator_,\n",
    "SVR(set_kernel = set_per_kernel),\n",
    "data_accumulator(), **codpy_param, **svm_param)\n",
    "results = scenario_generator_.accumulator.get_output_datas().dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4e30ea",
   "metadata": {},
   "source": [
    "Figure \\@ref(fig:1013) shows the results of the first two scenarios of this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc241e6",
   "metadata": {
    "fig.cap": "SVM",
    "label": 1013
   },
   "outputs": [],
   "source": [
    "list_results = [(s.z,s.f_z) for s in scenario_generator_.accumulator.predictors]\n",
    "multi_plot(list_results,plot1D,mp_max_items = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8153c499",
   "metadata": {},
   "source": [
    "Table \\@ref(tab:1012) provides all computed indicators after running all scenarios indicated in the Table  \\@ref(tab:299)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45aaffe",
   "metadata": {
    "label": 1012
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results,  caption = \"SVM performance indicators\", col.names = c(\"$predictor_{id}$\", \"$D$\", \"$N_x$\", \"$N_y$\", \"$N_z$\", \"$D_f$\", \"time\", \"scores\", \"norm function\", \"discr.error\"), escape = FALSE)%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12d70a6",
   "metadata": {},
   "source": [
    "##  Benchmark methodology: neural network predictors\n",
    "\n",
    "### TensorFlow neural network regression model\n",
    "\n",
    "For this test, we use as an interpolation machine a standard neural network one, taken from TensorFlow, commonly called **deep learning** method. It consists in a network of *layers* defined by the following settings, see [this dedicated page for a description of TensorFlow neural networks](https://www.tensorflow.org/tutorials/customization/basics). The reader can tune this set of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e81b9c",
   "metadata": {
    "echo": true,
    "include": true,
    "show": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "codpy_param['tfRegressor'] = {'epochs': 50,\n",
    "'batch_size':16,\n",
    "'validation_split':0.1,\n",
    "'loss':tf.keras.losses.mean_squared_error,\n",
    "'optimizer':tf.keras.optimizers.Adam(0.001),\n",
    "'layers':[8,64,64,1],\n",
    "'activation':['relu','relu','relu','linear'],\n",
    "'metrics':['mse']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893c346",
   "metadata": {},
   "source": [
    "We then run the scenarios. We plot the two first results of this test in Figure \\@ref(fig:xfxzfzbl) : these are the predictions, denoted $f_z$, of the function $f(z)$; see figure \\@ref(fig:xfxzfz), for the first two scenarios defined in Table \\@ref(tab:299)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb00b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_generator_.run_scenarios(scenarios_list,data_random_generator_,tfRegressor(set_kernel = set_per_kernel),data_accumulator(), **codpy_param)\n",
    "results = scenario_generator_.accumulator.get_output_datas().dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb65447",
   "metadata": {
    "fig.cap": "TensorFlow : two predictions.",
    "label": "#R_CODE#xfxzfzbl"
   },
   "outputs": [],
   "source": [
    "list_results = [(s.z,s.f_z) for s in scenario_generator_.accumulator.predictors]\n",
    "multi_plot(list_results,plot1D,mp_max_items = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145321f4",
   "metadata": {},
   "source": [
    "The table \\@ref(tab:569) shows computed indicators after running all scenarios indicated in Table  \\@ref(tab:299). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4accde1",
   "metadata": {
    "fig.cap": "indicators for a deep learning method.",
    "label": 569
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results,  caption = \"Tensorflow neural network performance indicators\", col.names = c(\"$predictor_{id}$\", \"$D$\", \"$N_x$\", \"$N_y$\", \"$N_z$\", \"$D_f$\", \"time\", \"scores\", \"norm function\", \"discr.error\"), escape = FALSE)%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d935a68a",
   "metadata": {},
   "source": [
    "### Pytorch neural network regression model\n",
    "\n",
    "For this test, we use as interpolation machine a standard neural network one, taken from Pytorch. It consists in a network of *layers* defined by the following settings, see [this dedicated page for a description of Pytorch neural networks](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html). We constructed the same neural network as in the case of Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a66d42c",
   "metadata": {
    "echo": true,
    "include": true,
    "show": true
   },
   "outputs": [],
   "source": [
    "torch_param = {'PytorchRegressor': {'epochs': 128,\n",
    "'layers': [8,64,64],\n",
    "'activation':['relu','linear'],\n",
    "'batch_size': 16,\n",
    "'loss': nn.MSELoss(),\n",
    "'activation': nn.ReLU(),\n",
    "'optimizer': torch.optim.Adam,\n",
    "\"out_layer\": 1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c660d",
   "metadata": {
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "scenario_generator_.run_scenarios(scenarios_list,\n",
    "data_random_generator_,\n",
    "PytorchRegressor(set_kernel = set_per_kernel),\n",
    "data_accumulator(), **codpy_param, **torch_param)\n",
    "results = scenario_generator_.accumulator.get_output_datas().dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ffe911",
   "metadata": {},
   "source": [
    "Figure \\@ref(fig:1001) shows the results of first two scenarios of this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0fcb3c",
   "metadata": {
    "fig.cap": "Pytorch",
    "label": 1001
   },
   "outputs": [],
   "source": [
    "list_results = [(s.z,s.f_z) for s in scenario_generator_.accumulator.predictors]\n",
    "multi_plot(list_results,plot1D,mp_max_items = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae7bf5e",
   "metadata": {},
   "source": [
    "We run the scenarios and output the results: Table \\@ref(tab:1000) provides all computed indicators after running all scenarios indicated in Table  \\@ref(tab:299). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f4cc4e",
   "metadata": {
    "label": 1000
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results, caption = \"Pytorch performance indicators\", col.names = c(\"$predictor_{id}$\", \"$D$\", \"$N_x$\", \"$N_y$\", \"$N_z$\", \"$D_f$\", \"time\", \"scores\", \"norm function\", \"discr.error\"), escape = FALSE) %>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894f64c9",
   "metadata": {},
   "source": [
    "##  Benchmark methodology: regression-tree predictors\n",
    "\n",
    "### Decision tree regression\n",
    "\n",
    "We use as interpolation machine a decision tree, taken from scikit learn. It allows to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. A tree can be seen as a piecewise constant approximation; see [this dedicated page for a description of decision trees](https://scikit-learn.org/stable/modules/tree.html). (The reader can tune this set of parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a804d86e",
   "metadata": {
    "echo": true,
    "include": true,
    "lines_to_next_cell": 2,
    "show": true
   },
   "outputs": [],
   "source": [
    "DT_param = {'max_depth': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e17780a",
   "metadata": {
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "scenario_generator_.run_scenarios(scenarios_list,\n",
    "data_random_generator_,\n",
    "DecisionTreeRegressor(set_kernel = set_per_kernel),\n",
    "data_accumulator(), **codpy_param, **DT_param)\n",
    "results = scenario_generator_.accumulator.get_output_datas().dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226efb8f",
   "metadata": {},
   "source": [
    "Figure \\@ref(fig:1003) shows the results of the first two scenarios of this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba317c8",
   "metadata": {
    "fig.cap": "Decision Tree",
    "label": 1003
   },
   "outputs": [],
   "source": [
    "list_results = [(s.z,s.f_z) for s in scenario_generator_.accumulator.predictors]\n",
    "multi_plot(list_results,plot1D,mp_max_items = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef53e10",
   "metadata": {},
   "source": [
    "Table \\@ref(tab:1002) provides all computed indicators after running all scenarios indicated in Table \\@ref(tab:299)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dad813",
   "metadata": {
    "label": 1002
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results, caption = \"Decision Tree performance indicators\", col.names = c(\"$predictor_{id}$\", \"$D$\", \"$N_x$\", \"$N_y$\", \"$N_z$\", \"$D_f$\", \"time\", \"scores\", \"norm function\", \"discr.error\"), escape = FALSE)%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdc3e65",
   "metadata": {},
   "source": [
    "### AdaBoost regression\n",
    "\n",
    "Now, for the interpolation machine we use an AdaBoost algorithm, taken from scikit learn. The core principle of AdaBoost is to fit a sequence of weak learners (i.e., models that are only slightly better than random guessing, such as small decision trees) on repeatedly modified versions of the data. The predictions from all of them are then combined through a weighted majority vote (or sum) to produce the final prediction, see [this dedicated page for a description of AdaBoost algorithm](https://scikit-learn.org/stable/modules/ensemble.html#adaboost). The reader can tune this set of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72e05cf",
   "metadata": {
    "echo": true,
    "include": true,
    "lines_to_next_cell": 2,
    "show": true
   },
   "outputs": [],
   "source": [
    "ada_param = {'tree_no': 50, 'learning_rate': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5eb71f",
   "metadata": {
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "scenario_generator_.run_scenarios(scenarios_list,\n",
    "data_random_generator_,\n",
    "AdaBoostRegressor(set_kernel = set_per_kernel),\n",
    "data_accumulator(), **codpy_param, **ada_param)\n",
    "results = scenario_generator_.accumulator.get_output_datas().dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033be966",
   "metadata": {},
   "source": [
    "Figure \\@ref(fig:1005) shows the results of the first two scenarios of this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275ed997",
   "metadata": {
    "fig.cap": "AdaBoost",
    "label": 1005
   },
   "outputs": [],
   "source": [
    "list_results = [(s.z,s.f_z) for s in scenario_generator_.accumulator.predictors]\n",
    "multi_plot(list_results,plot1D,mp_max_items = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b1019b",
   "metadata": {},
   "source": [
    "Table \\@ref(tab:1004) provides all computed indicators after running all scenarios indicated in Table  \\@ref(tab:299). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb16539",
   "metadata": {
    "label": 1004,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results, caption = \"AdaBoost performance indicators\", col.names = c(\"$predictor_{id}$\", \"$D$\", \"$N_x$\", \"$N_y$\", \"$N_z$\", \"$D_f$\", \"time\", \"scores\", \"norm function\", \"discr.error\"), escape = FALSE)%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a10045",
   "metadata": {},
   "source": [
    "### Gradient boosting regression\n",
    "\n",
    "For this test, we use as interpolation machine a gradient decision tree boosting (GBDT), taken from scikit learn.  It allows for the optimization of arbitrary differentiable loss functions. In each stage a regression tree is fit on the negative gradient of the given loss function; see [this dedicated page for a description of Gradient Tree Boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting). (The reader can tune this set of parameters.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c45bd5a",
   "metadata": {
    "echo": true,
    "include": true,
    "show": true
   },
   "outputs": [],
   "source": [
    "gb_param = {'tree_no': 50, 'learning_rate': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bcf3cf",
   "metadata": {
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "scenario_generator_.run_scenarios(scenarios_list,\n",
    "data_random_generator_,\n",
    "GradientBoostingRegressor(set_kernel = set_per_kernel),\n",
    "data_accumulator(), **codpy_param, **gb_param)\n",
    "results = scenario_generator_.accumulator.get_output_datas().dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f01402",
   "metadata": {},
   "source": [
    "Figure \\@ref(fig:1007) shows the results of the first two scenarios of this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370b335",
   "metadata": {
    "fig.cap": "Gradient Boosting",
    "label": 1007
   },
   "outputs": [],
   "source": [
    "list_results = [(s.z,s.f_z) for s in scenario_generator_.accumulator.predictors]\n",
    "multi_plot(list_results,plot1D,mp_max_items = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d0a661",
   "metadata": {},
   "source": [
    "Table \\@ref(tab:1006) provides all computed indicators after running all scenarios indicated in Table  \\@ref(tab:299)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fc189d",
   "metadata": {
    "label": 1006
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results, caption = \"Gradient Boosting performance indicators\", col.names = c(\"$predictor_{id}$\", \"$D$\", \"$N_x$\", \"$N_y$\", \"$N_z$\", \"$D_f$\", \"time\", \"scores\", \"norm function\", \"discr.error\"), escape = FALSE)%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45645fd",
   "metadata": {},
   "source": [
    "### XGBoost algorithm\n",
    "\n",
    "For this test, we use as XGBoost as an interpolation machine. It is essentially a computationally efficient implementation of the original gradient\n",
    "boost algorithm, see [this dedicated page for a description of XGBoost project](https://xgboost.readthedocs.io/en/latest/tutorials/model.html). (The reader can tune this set of parameters.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784c8529",
   "metadata": {
    "echo": true,
    "include": true,
    "show": true
   },
   "outputs": [],
   "source": [
    "xgb_param = {'max_depth': 5, 'n_estimators': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84845ed5",
   "metadata": {
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "scenario_generator_.run_scenarios(scenarios_list,\n",
    "data_random_generator_,\n",
    "XGBRegressor(set_kernel = set_per_kernel),\n",
    "data_accumulator(), **codpy_param, **xgb_param)\n",
    "results = scenario_generator_.accumulator.get_output_datas().dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0e1390",
   "metadata": {},
   "source": [
    "Figure \\@ref(fig:1009) shows the results of the first two scenarios of this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff1492",
   "metadata": {
    "fig.cap": "XGBoost",
    "label": 1009
   },
   "outputs": [],
   "source": [
    "list_results = [(s.z,s.f_z) for s in scenario_generator_.accumulator.predictors]\n",
    "multi_plot(list_results,plot1D,mp_max_items = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80644ff1",
   "metadata": {},
   "source": [
    "Table \\@ref(tab:1008) provides all computed indicators after running all scenarios indicated in Table  \\@ref(tab:299)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dbcb54",
   "metadata": {
    "label": 1008
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results, caption = \"XGBoost performance indicators\", col.names = c(\"$predictor_{id}$\", \"$D$\", \"$N_x$\", \"$N_y$\", \"$N_z$\", \"$D_f$\", \"time\", \"scores\", \"norm function\", \"discr.error\"), escape = FALSE)%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c13528",
   "metadata": {},
   "source": [
    "### Random forest regression\n",
    "\n",
    "For this test, as an interpolation machine we use a random forest regression.  It operates by constructing a large number of decision trees at training time and producing the class that is the mode of the classes (classification) or mean/average prediction (regression) of the individual trees; see [this dedicated page for a description of forests of randomized trees](https://scikit-learn.org/stable/modules/ensemble.html#forest). (The reader can tune this set of parameters.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ebce2",
   "metadata": {
    "echo": true,
    "include": true,
    "show": true
   },
   "outputs": [],
   "source": [
    "RF_param = {'max_depth': 5, 'n_estimators': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff34740",
   "metadata": {
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "scenario_generator_.run_scenarios(scenarios_list,\n",
    "data_random_generator_,\n",
    "RandomForestRegressor(set_kernel = set_per_kernel),\n",
    "data_accumulator(), **codpy_param, **RF_param)\n",
    "results = scenario_generator_.accumulator.get_output_datas().dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5610af6b",
   "metadata": {},
   "source": [
    "Figure \\@ref(fig:1011) shows the results of first two scenarios of this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c562eb98",
   "metadata": {
    "fig.cap": "Random Forest",
    "label": 1011
   },
   "outputs": [],
   "source": [
    "list_results = [(s.z,s.f_z) for s in scenario_generator_.accumulator.predictors]\n",
    "multi_plot(list_results,plot1D,mp_max_items = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fb787d",
   "metadata": {},
   "source": [
    "Table \\@ref(tab:1010) provides all computed indicators after running all scenarios indicated in Table  \\@ref(tab:299)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e13ddc",
   "metadata": {
    "label": 1010
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results, caption = \"Random Forest performance indicators\", col.names = c(\"$predictor_{id}$\", \"$D$\", \"$N_x$\", \"$N_y$\", \"$N_z$\", \"$D_f$\", \"time\", \"scores\", \"norm function\", \"discr.error\"), escape = FALSE)%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66307bf",
   "metadata": {},
   "source": [
    "### A comparison between methods\n",
    "\n",
    "We benchmark methods, comparing any computed indicators as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943052d4",
   "metadata": {
    "fig.cap": "Benchmarking scores (RMSE)",
    "fig.height": 2,
    "label": "#R_CODE#0004",
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "scenario_generator_.compare_plots(\n",
    "axis_field_labels = [(\"Nx\",\"scores\")],\n",
    "mp_title = \"Benchmark methods\",mp_ncols=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41565405",
   "metadata": {
    "fig.cap": "Discrepancy error",
    "label": "#R_CODE#0005",
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "scenario_generator_.compare_plots(\n",
    "axis_field_labels = [(\"Nx\",\"discrepancy_errors\")],\n",
    "mp_title = \"Benchmark methods\",mp_ncols=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24089bd5",
   "metadata": {
    "fig.cap": "Computation time comparison",
    "label": "#R_CODE#0006",
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "scenario_generator_.compare_plots(\n",
    "axis_field_labels = [(\"Nx\",\"execution_time\")],\n",
    "mp_title = \"Benchmark methods\",mp_ncols=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb1ec4b",
   "metadata": {},
   "source": [
    "Observe that function norms and discrepancy errors are not method-dependent. Clearly, for this example, a periodical kernel-based method outperforms the two other ones. However, it is not our goal to illustrate a particular method supremacy, but a benchmark methodology, particularly in the context of extrapolating test set data far from the training set ones.\n",
    "\n",
    "## Tutorial in $N$ dimensions \n",
    "\n",
    "### Initialization\n",
    "\n",
    "Now we illustrate the fact that the dimension arising in the problem under consideration does not change benchmark methods. To illustrate this point, we simply copy/paste the previous step used for the one-dimensional case, but setting the dimension to two, that is $D=2$, and the user can test with this parameter. Only data visualization changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c374323",
   "metadata": {
    "fig.cap": "training and test set.",
    "label": "#R_CODE#xfxzfzd",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "data_random_generator_ = data_random_generator(fun = my_fun,types=[\"cart\",\"sto\",\"cart\"])\n",
    "x, fx, y, fy, z, fz =  data_random_generator_.get_data(D=1,Nx=100,Ny=100,Nz=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3652b29",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We first pick-up a scenario list, see Table \\@ref(tab:879), to be compared to the one-dimensional scenario Table \\@ref(tab:299)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e477792a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "D = 2\n",
    "scenarios_list = [ (D, 100*(i**2), 100*(i**2),100*(i**2) ) for i in np.arange(5,1,-1)]\n",
    "pd_scenarios_list = pd.DataFrame(scenarios_list,columns = [\"D\",\"Nx\",\"Ny\",\"Nz\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c716dc",
   "metadata": {
    "label": 879,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$pd_scenarios_list, caption = \"scenario list\", col.names = c(\"$D$\",\"$N_x$\",\"$N_y$\",\"$N_z$\"), escape = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1daccc",
   "metadata": {},
   "source": [
    "Then we generate data and in Figure \\@ref(fig:xfxzfz2) we show both graphs $(x,f(x))$ (left, training set),$(z,f(z))$ (right, test set) for illustration purposes, $f$ being defined in Section \\@ref(2D). Observe that, if the dimension is greater to two, we use a two dimensional visualization, plotting $\\tilde{x},f(x)$, where $\\tilde{x}$ is obtained\n",
    "\n",
    "* either setting indices $\\tilde{x}:=x[index1,index2]$\n",
    "* or performing a PCA over $x$ and setting $\\tilde{x}:=PCA(x)[index1,index2]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7316b5a",
   "metadata": {
    "fig.cap": "train vs test set.",
    "label": "#R_CODE#xfxzfz2"
   },
   "outputs": [],
   "source": [
    "data_random_generator_ = data_random_generator(fun = my_fun, types=[\"cart\",\"sto\",\"cart\"])\n",
    "x, fx, y, fy, z, fz =  data_random_generator_.get_data(D=D,Nx=2000,Ny=2000,Nz=2000)\n",
    "multi_plot([(x,fx),(z,fz)],plot_trisurf,projection='3d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939b030b",
   "metadata": {},
   "source": [
    "### Periodic kernel for machine learning\n",
    "\n",
    "This defines a standard periodic Gaussian kernel, with a linear regression kernel, allowing us to fit both periodical and polynomial parts of our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d42d9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_generator_ = scenario_generator()\n",
    "scenario_generator_.run_scenarios(scenarios_list,data_random_generator_,\n",
    "codpyexRegressor(set_kernel = set_per_kernel),\n",
    "data_accumulator(),data_generator_crop = False, **codpy_param)\n",
    "results = scenario_generator_.accumulator.get_output_datas().dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fa08b1",
   "metadata": {},
   "source": [
    "Table \\@ref(tab:657) shows the computed indicators after running all scenarios indicated in Table  \\@ref(tab:299)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c3e68",
   "metadata": {
    "fig.cap": "indicator for periodic kernel.",
    "label": 657
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results,  caption = \"CodPy performance indicators\", col.names = c(\"$predictor_{id}$\", \"$D$\", \"$N_x$\", \"$N_y$\", \"$N_z$\", \"$D_f$\", \"time\", \"scores\", \"norm function\", \"discr.error\"), escape = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d770232b",
   "metadata": {},
   "source": [
    "We plot the first two results of this test: the predictions, denoted $f_z$, of the function $f(z)$; see Figure \\@ref(fig:xfxzfz2), for the first two scenarios defined in Table \\@ref(tab:299)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6701524a",
   "metadata": {
    "fig.cap": "Codpy via periodic kernel: train vs test set",
    "label": "#R_CODE#0007"
   },
   "outputs": [],
   "source": [
    "list_results = [(s.z,s.f_z) for s in scenario_generator_.accumulator.predictors]\n",
    "multi_plot(list_results,plot_trisurf,mp_max_items = 2,projection='3d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2a4bea",
   "metadata": {},
   "source": [
    "### Scipy library\n",
    "\n",
    "In this section we present the result of an extrapolation using SciPy's function RBF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0bb774",
   "metadata": {
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "scenario_generator_.run_scenarios(scenarios_list,data_random_generator_,\n",
    "ScipyRegressor(set_kernel = set_per_kernel),\n",
    "data_accumulator(), data_generator_crop = False,**codpy_param)\n",
    "results = scenario_generator_.accumulator.get_output_datas().dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5241e4bc",
   "metadata": {},
   "source": [
    "We provide all computed indicators after running all scenarios indicated in  Table \\@ref(tab:299)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab76db58",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results,  caption = \"scipy performance indicators\", col.names = c(\"$predictor_{id}$\", \"$D$\", \"$N_x$\", \"$N_y$\", \"$N_z$\", \"$D_f$\", \"time\", \"scores\", \"norm function\", \"discr.error\"), escape = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3194115",
   "metadata": {},
   "source": [
    "We end this test plotting the two first results of this test, to be compared to Figure \\@ref(fig:xfxzfz2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3bf2d1",
   "metadata": {
    "fig.cap": "Scipy: train set vs test set",
    "label": "#R_CODE#0008"
   },
   "outputs": [],
   "source": [
    "list_results = [(s.z,s.f_z) for s in scenario_generator_.accumulator.predictors]\n",
    "multi_plot(list_results,plot_trisurf,title=\"z, f(z)\",mp_max_items = 2,projection='3d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c99cc48",
   "metadata": {},
   "source": [
    "### A comparison between methods\n",
    "\n",
    "Methods are compared in the corresponding figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac183059",
   "metadata": {
    "fig.cap": "benchmark of various performance indicators for supervised learning",
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "scenario_generator_.compare_plots(\n",
    "axis_field_labels = [(\"Nx\",\"scores\"),(\"Nx\",\"discrepancy_errors\"),(\"Nx\",\"execution_time\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cac66a",
   "metadata": {},
   "source": [
    "## Benchmark methodology for unsupervised learning\n",
    "\n",
    "### Purpose \n",
    "\n",
    "The goal of this section is to overview our own methodology (which will be fully described in the next chapter).\n",
    "\n",
    "* We illustrate the prediction function $\\mathcal{P}_m$ for some methods in the context of supervised learning.\n",
    "* We illustrate the computations of some performance indicators, as well as to present a toy benchmark using these indicators.\n",
    "\n",
    "The data is generated using a multi-modal, multi-variate, Gaussian distribution with a covariance matrix $\\Sigma = \\sigma I_d$. The problem is to identify the modes of the distribution using clustering method.\n",
    "In the following we will generate distribution with a predetermined number of modes, it will allow to test validation scores on this toy example.\n",
    "\n",
    "###  Analysis via k-means clustering\n",
    "\n",
    "In this paragraph, we compute k-means clustering, using a scikit-learn implementation[^201]\n",
    "\n",
    "[^201]:[the scikit-learn implementation is available using this link](https://scikit-learn.org/stable/modules/clustering.html#k-means)\n",
    "\n",
    "We first run all scenarios. We provide all computed indicators after running all scenarios indicated in Table \\@ref(tab:299)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30126d72",
   "metadata": {
    "tags": [
     "remove_cell",
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "from clusteringCHK import *\n",
    "set_kernel = set_gaussian_kernel\n",
    "scenarios_list = [ (2, 1000, i,1000 ) for i in np.arange(2,7,1)]\n",
    "scenario_generator_ = scenario_generator()\n",
    "scenario_generator_.run_scenarios(scenarios_list,data_blob_generator(),scikitClusterClassifier(set_kernel = set_kernel),cluster_accumulator(), **codpy_param)\n",
    "results = scenario_generator_.accumulator.get_output_datas().dropna(axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392dc1e3",
   "metadata": {
    "results": "asis",
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "pyresults <- py$results\n",
    "row.names(pyresults) <-  c(\"$predictor_{id}$\", \"$D$\", \"$N_x$\", \"$N_y$\", \"$N_z$\", \"$D_f$\", \"time\", \"scores\", \"norm function\", \"discr.error\", \"score calinsky\", \"score harabazs\", \"homogeneity test\", \"inertia\")\n",
    "knitr::kable(pyresults,  caption = \"scikit: clusters indicators\", escape = FALSE, col.names = NULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b1ed2b",
   "metadata": {},
   "source": [
    "**k-means blob visualization**. We now plot the first two distributions as well as the corresponding computed clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a814367",
   "metadata": {
    "fig.cap": "Scatter plot of clusters using scikit k-means",
    "label": "#R_CODE#0009",
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "scenario_generator_.accumulator.plot_clusters(**codpy_param, index1=0,index2=1,xlabel = 'x',ylabel = 'y',mp_max_items = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659d695c",
   "metadata": {},
   "source": [
    "**k-means confusion matrix**. We next plot the first two confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d484f",
   "metadata": {
    "fig.cap": "Confusion matrices of scikit kmeans",
    "label": "#R_CODE#00010",
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "scenario_generator_.accumulator.plot_confusion_matrices(mp_max_items = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2045b299",
   "metadata": {},
   "source": [
    "### Analysis via mini-batch clustering\n",
    "\n",
    "To compute minibatch clustering, we use [scikit-learn implementation](https://scikit-learn.org/stable/modules/clustering.html#mini-batch-kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce7084a",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "remove_cell",
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "scenario_generator_.run_scenarios(scenarios_list,data_blob_generator(),MinibatchClusterClassifier(set_kernel = set_kernel),cluster_accumulator(), **codpy_param)\n",
    "results = scenario_generator_.accumulator.get_output_datas().dropna(axis=1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af15047f",
   "metadata": {},
   "source": [
    "We provide all computed indicators after running all scenarios indicated in  Table \\@ref(tab:299)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93317fae",
   "metadata": {
    "results": "asis",
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "pyresults <- py$results\n",
    "row.names(pyresults) <-  c(\"$predictor_{id}$\", \"$D$\", \"$N_x$\", \"$N_y$\", \"$N_z$\", \"$D_f$\", \"time\", \"scores\", \"norm function\", \"discr.error\", \"scores calinsky\", \"score harabazs\", \"homogeneity test\", \"inertia\")\n",
    "knitr::kable(pyresults,  caption = \"Minibatch: clusters indicators\", escape = FALSE, col.names = NULL) %>%\n",
    "  kable_styling(full_width = T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12950b17",
   "metadata": {},
   "source": [
    "**Minibatch blob visualization**. We next plot the first two distributions as well as the corresponding computed clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935a84c9",
   "metadata": {
    "fig.cap": "Scatter plots of scikit minibatch kmeans",
    "label": "#R_CODE#00011",
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "scenario_generator_.accumulator.plot_clusters(**codpy_param, index1=0,index2=1,xlabel = 'x',ylabel = 'y',mp_max_items = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f748e6",
   "metadata": {},
   "source": [
    "**Minibatch confusion matrix**. The figure below illustrates two confusion matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d9119",
   "metadata": {
    "fig.cap": "Confusion matrices of scikit minibatch kmeans",
    "label": 751,
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "scenario_generator_.accumulator.plot_confusion_matrices(mp_max_items = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8e6f90",
   "metadata": {},
   "source": [
    "### Analysis via CodPy clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55d7d93",
   "metadata": {
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "scenario_generator_.run_scenarios(scenarios_list,data_blob_generator(),codpyClusterPredictor(set_kernel = set_kernel),cluster_accumulator(), **codpy_param)\n",
    "results = scenario_generator_.accumulator.get_output_datas().dropna(axis=1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6c3f68",
   "metadata": {},
   "source": [
    "We also provide all the indicators after running all of the scenarios in Table  \\@ref(tab:299)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb5044c",
   "metadata": {
    "lines_to_next_cell": 0,
    "results": "asis"
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "pyresults <- py$results\n",
    "row.names(pyresults) <-  c(\"$predictor_{id}$\", \"$D$\", \"$N_x$\", \"$N_y$\", \"$N_z$\", \"$D_f$\", \"time\", \"scores\", \"norm function\", \"discr.error\", \"score calinsky\", \"score harabazs\", \"homogeneity test\", \"inertia\")\n",
    "knitr::kable(pyresults,  caption = \"codpy: clusters indicators\", escape = FALSE, col.names = NULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e478bc20",
   "metadata": {},
   "source": [
    "**CodPy blob visualization**. We finally plot the two first distributions as well as the corresponding computed clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90849440",
   "metadata": {
    "fig.cap": "Scatter plots of codpy clustering algorithm",
    "label": "#R_CODE#00013",
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "scenario_generator_.accumulator.plot_clusters(**codpy_param, index1=0,index2=1,xlabel = 'x',ylabel = 'y',mp_max_items = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2acf0b",
   "metadata": {},
   "source": [
    "**CodPy confusion matrix**. The figure below illustrates two confusion matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ae460e",
   "metadata": {
    "codecap": "codpy confusion matrix",
    "fig.cap": "Confusion matrices of codpy clustering algorithm",
    "label": 750,
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "scenario_generator_.accumulator.plot_confusion_matrices(mp_max_items = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4c5aea",
   "metadata": {},
   "source": [
    "### A comparison between methods\n",
    "\n",
    "We compare the various methods under consideration, by comparing performance indicators, as illustrated by Figure \\@ref(fig:740). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5788e937",
   "metadata": {
    "fig.cap": "benchmark of various performance indicators for clustering.",
    "label": 740,
    "lines_to_next_cell": 0,
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "scenario_generator_.compare_plots(\n",
    "axis_field_labels = [(\"Ny\",\"scores\"),(\"Ny\",\"discrepancy_errors\"),(\"Ny\",\"inertia\"),(\"Ny\",\"execution_time\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7b12c0",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "name,results,echo,include,show,label,fig.height,codecap,fig.cap,tags,code,eval,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
