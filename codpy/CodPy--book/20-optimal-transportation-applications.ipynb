{
 "cells": [
  {
   "cell_type": "raw",
   "id": "18a9aa56",
   "metadata": {},
   "source": [
    "---\n",
    "output:\n",
    "  pdf_document:\n",
    "    keep_tex: yes\n",
    "    includes:\n",
    "      in_header: preamble.tex\n",
    "  html_document: default\n",
    "  word_document: default\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092c8d0b",
   "metadata": {
    "code": "#R_CODE#xfun::read_utf8('preamble.R')",
    "lines_to_next_cell": 2,
    "tags": [
     "remove_cell",
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "%%R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de92f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preamble import *\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffc9d97",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from Bachelier import *\n",
    "from BTC_predictor import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e6a407",
   "metadata": {},
   "source": [
    "# Application to optimal transport\n",
    "\n",
    "## Bachelier problem\n",
    "\n",
    "### Introduction\n",
    "\n",
    "The purpose of this test is to benchmark the Pi-function, see section \\ref{the-conditional-expectation-algorithm} with the Bachelier problem, that is described in the next section. \n",
    "\n",
    "It is known since a decade that deep learning methods can be described by kernel methods, see for instance \\cite{HJW}. We illustrate this fact with a kernel method, designed with a quite comparable spirit to the Neural network approach. Indeed, this method gives quite comparable results to the NN one : both methods are not convergent, and we do not advise their use for critical applications.\n",
    "\n",
    "### Problem description\n",
    "\n",
    "* Consider a martingale process $t \\mapsto X(t) \\in \\RR^D$, given by the Brownian motion $dX=\\sigma dW_t$, where the matrix $\\sigma \\in \\RR^{D \\times D}$ is randomly generated. The initial condition is $X(0)=(1,\\cdots,1)$, w.l.o.g."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba8dd5e",
   "metadata": {},
   "source": [
    "* Consider two times $1=t^1<t^2=2$, $t^2$ being the maturity of an option, that is a function denoted $P(x) = \\max(b(x)-K,0)$, where $K=1.1$, $b(x) := x \\cdot a$ with random weights $a \\in \\RR^D$. It is straightforward to verify that $b(x)$ follows a Brownian motion $db = \\theta dW_t$. To get a fixed value for $\\theta$ (fixed to 0.2 in our tests), we normalize the diffusion matrix $\\sigma$ above.\n",
    "\n",
    "* The goal of this test is to benchmark numerical methods aiming to compute the following conditional expectation\n",
    "$$\n",
    "  f(z) := \\EE^{X(t^2)}\\Big( P(\\cdot) | X(t^1) = z \\Big).\n",
    "$$\n",
    "For the Bachelier problem, this last quantity can be determined using a closed formula : the reference value is computed as\n",
    "\\begin{equation}\\label{BACH}\n",
    "  f(z) = \\theta \\sqrt{t^2 - t^1} pdf(d) + (b(x)-K) cdf(d),\\quad d(x,K) := \\frac{b(x)-K}{\\theta \\sqrt{t^2 - t^1}}\n",
    "\\end{equation}\n",
    "pdf (resp. cdf) holding for the probability density function (resp. cumulative) of the normal law.\n",
    "\n",
    "### Methodology, Notations, input and output data\n",
    "\n",
    "For our tests, we use the following notations, and precise their signification for this report, and more generally for Finance applications:\n",
    "\n",
    "* $x \\in \\RR^{ N_x \\times D}$ denotes the training set of variables. For our test, this set is given by iid samples of the brownian motion $X(t)$ at time $t^1 = 1$. \n",
    "  + For quantitative Finance applications, this set typically consists in $N_x$ iid samples of a stochastic process $t \\mapsto X(t) \\in \\RR^D$ at a time $t$. Such samples might be generated by discretization of stochastic processes using Euler methods for instance.\n",
    "- $f(x) \\in \\RR^{ N_x \\times D_f}$ denotes the training set of values. It is generated as $P(X(t^2) | x)$, $P$ being the payoff of the option described in the previous section, $x$ being the training set.\n",
    "  + For Finance applications, $f \\in \\mathcal{C}^1(\\RR^D)^M$ is usually a derivable function, having vector valued values corresponding to payoffs, or investment strategies, of portfolios.\n",
    "- $z \\in \\RR^{ N_z \\times D}$ denotes the test set of variables. It consists for our test as another iid realization of the brownian motion $X(t)$ at time $t^1 = 1$.\n",
    "  + This set represent usually a set of user defined samples of underlying risks, chosen accordingly to its needs. \n",
    "- $f(z) \\in \\RR^{ N_z \\times D_f}$ is the set of reference values, computed using \\eqref{BACH} ($D_f = 1$ in this experiment)\n",
    "  + This set consists in  reference - ground truth - values, approximating $P(z):= \\EE\\big(f(x_{t^2} | z)\\big)$. \n",
    "  \n",
    "To these set we added another one, used for internal computations\n",
    "\n",
    "- $y \\in \\RR^{ N_y \\times D}$, with $N_y << N_x$.\n",
    "  + This set corresponds to the weight set for neural networks methods.\n",
    "  + This set corresponds to what we call a \"projection set\" for kernel methods (see \\cite{MM1} for a definition)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b83ce4",
   "metadata": {},
   "source": [
    "Output data are\n",
    "\n",
    "- $f_z \\in \\RR^{ N_z \\times D_f}$ the set of predicted values. These are the values that are benchmarked against $f(z)$ in our experiments.\n",
    "\n",
    "For each numerical experiments, we output a table summarizing the values of $N_x,N_y,N_z,D$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345759a8",
   "metadata": {},
   "source": [
    "### Four methods to tackle the Bachelier problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e107bc",
   "metadata": {},
   "source": [
    "In this technical report, we compare four methods for tackling the computation of conditional expectations for the Bachelier problem :\n",
    "\n",
    "1. The first is a Neural Network one, using Tensorflow to retrieve results. Code can be downloaded at \\cite{AS1}, the method itself is described in \\cite{NS}.\n",
    "\n",
    "2. The second one is a standard kernel method, quite comparable to the previous approach, using codpy implementation of kernel methods, that is the textit {projection} function\n",
    "\n",
    "\\begin{equation}\\label{proj}\n",
    "  P^k(x,y,z,f(z)=[]) = k(z,y) k(x,y)^{-1}f(z)\n",
    "\\end{equation}\n",
    "where $y$ is a $N_y$-size random shuffling of the initial set $x$, and $k(x,y)$ is a Gram matrix, see \\cite{MM} for a more detailed description.\n",
    "\n",
    "3. The third one uses the Pi function above, where $x$ (resp. $z$) are iid sequences of $X(t^1)$ (resp. $X(t^2)$), as presented in the above section.\n",
    "\n",
    "4.  The fourth one uses also the Pi function above, but choosing $x$ (resp. $z$) as sharp discrepancy sequences of $X(t^1)$, (resp. $X(t^2)$) see \\cite{LM3} - \\cite{LM1}."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6277d156",
   "metadata": {},
   "source": [
    "### Test specification\n",
    "\n",
    "A single test relies on 8 parameters, that we list below. We will be running several scenario to benchmark our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e8cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(matrix(c('# xs','# ys','# zs','Dimension','Generator x','Generator z | x','Generator z'),nrow=1,ncol=7),caption = 'A test specification', col.names = c('Nx','Ny','Nz', 'D', 's1','s2','s3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bceee3",
   "metadata": {},
   "source": [
    "Hence this numerical experiment uses $s_1,s_2,s_3$, three seeds for random generators:\n",
    "\n",
    "- $s_1$ is used to generate iid samples of $X(t^1)$ for the training set of variables $x$.\n",
    "\n",
    "- $s_2$ is used to generate iid samples of the conditional sampling $X(t^2) | X(t^1) = x$ for the training set of variables.\n",
    "\n",
    "- $s_3$ is used to generate iid samples of $X(t^1)$ for the test set of variables $z$.\n",
    "\n",
    "For instance, if $s_1 = s_3$, and $N_z < N_x$, then the test set is a subset of the training set $z \\subset x$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee6e4ca",
   "metadata": {},
   "source": [
    "To summarize the methodology, for each scenario of a given 8-uple $N_x,N_y,N_z,D,D_f, s_1,s_2,s_3$, each of our three methods output a prediction $f_z$, that is benchmarked against the ground-truth value $f(z)$. \n",
    "\n",
    "To measure errors, we use the percentage RMSE error, expressed as a real number between 0 and 1, called \\textbf{basis point error}, as follows:\n",
    "\n",
    "$$\n",
    "  RMSE\\%(f_z,f(z)) = \\frac{\\|f_z-f(z)\\|_{\\ell^2}}{\\|f_z\\|_{\\ell^2}+\\|f(z)\\|_{\\ell^2}} (\\#eq:RMSEper)\n",
    "$$\n",
    "\n",
    "We presents three tests. Two of them are two-dimensional ($D=2$), allowing graphical representation of input data and output errors to best illustrate our three methods. The third one is concerned with higher dimensional case.\n",
    "\n",
    "#### Input data settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e486497",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "codpy_param = {'rescale:xmax': 1000,\n",
    "'rescale:seed':42,\n",
    "'sharp_discrepancy:xmax':1000,\n",
    "'sharp_discrepancy:seed':30,\n",
    "'sharp_discrepancy:itermax':10,\n",
    "'discrepancy:xmax':500,\n",
    "'discrepancy:ymax':500,\n",
    "'discrepancy:zmax':500,\n",
    "'discrepancy:nmax':2000 \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db440e5",
   "metadata": {},
   "source": [
    "We generate our data set for the test, accordingly to the description given in the previous paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8a08aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bachelier import *\n",
    "D, Nx,Ny,Nz = 2, 300,300,300\n",
    "data_ = data_generator_Bachelier(seed1 = 42, seed2 = 35, seed3 = 42)\n",
    "data_.set_data(D, Nx,Ny,Nz)\n",
    "x,z,fx,fz = data_.x,data_.z,data_.fx,data_.fz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e477659",
   "metadata": {},
   "source": [
    "##### Training set for different times\n",
    "\n",
    "We plot $x=X(t^1)$ (training set), generated at time $t^1=1$ with $X(t^2) | X(t^1)$, that are the trajectories generated at time $t^2=2$. We plot a line between each $x$ and $z | x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf5d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=data_.variables(data_.T1,Nx,[],seed=data_.seed1)\n",
    "x2=data_.variables(data_.T2-data_.T1,Nx,x1,seed=data_.seed2)\n",
    "plt.scatter(x1[:,0],x1[:,1],color=\"red\")\n",
    "plt.scatter(x2[:,0],x2[:,1],color=\"green\")\n",
    "plt.plot([x1[:,0],x2[:,0]],[x1[:,1],x2[:,1]],color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8446c4e",
   "metadata": {},
   "source": [
    "##### Training values and ground test values distributions\n",
    "\n",
    "We plot the generated learning and test set in the following picture, comparing the variable $f(x)$ and the exact to predict $f(z)$, taking as x-axis the corresponding values of $b(x), b(z)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbfe0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "basketx = data_.basket(x = x)\n",
    "basketz = data_.basket(x = z)\n",
    "multi_plot([(basketx,fx),(basketz,fz)],plot1D,subtitles = ('input data','ground truth values'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e182519",
   "metadata": {},
   "source": [
    "### Running the tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca2d221",
   "metadata": {},
   "source": [
    "#### Standard Neural Network\n",
    "\n",
    "This test uses part of the code available at \\cite{AS1}. Our chosen scenarios are listed in Table \\@ref(tab:583)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5f8674",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_list = [ (2, 2**i, 80, 512)  for i in np.arange(5,16,1)]\n",
    "pd_scenarios_list = pd.DataFrame(scenarios_list,columns = [\"D\",\"Nx\",\"Ny\",\"Nz\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d77331",
   "metadata": {
    "label": 583
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$pd_scenarios_list, caption = \"scenario list\")%>%\n",
    "  kable_styling(full_width = T,font_size = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b87e16c",
   "metadata": {},
   "source": [
    "The Table \\@ref(tab:984) output the values of this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf5b55f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "data_generator_Bachelier_ = data_generator_Bachelier(seed1 = 42, seed2 = 35, seed3 = 42)\n",
    "scenario_generator_ = scenario_generator()\n",
    "scenario_generator_.run_scenarios(scenarios_list,data_generator_Bachelier_,NN_predictor_standard(set_kernel = set_sampler_kernel),data_accumulator(), **codpy_param)\n",
    "results = scenario_generator_.accumulator.get_output_datas().dropna(axis=1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c8f21a",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3980a59d",
   "metadata": {
    "label": 984,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results, caption = \"tensorflow indicators\")%>%\n",
    "  kable_styling(full_width = T,font_size = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ee9ff9",
   "metadata": {},
   "source": [
    "We output the predicted values $f_z$ against the exact ones $f(z)$, as  functions of the basket values $b(z)$ in Figure \\@ref(fig:585)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f559450",
   "metadata": {
    "fig.cap": "exact and predicted values for Tensoflow",
    "label": 585
   },
   "outputs": [],
   "source": [
    "basketzs = data_.basket(x = scenario_generator_.accumulator.get_zs())\n",
    "scenario_generator_.accumulator.plot_predicted_values(basketzs,labelx='Basket values',labely='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bb969d",
   "metadata": {},
   "source": [
    "#### Standard codpy kernel\n",
    "\n",
    "We provide the same approach with the kernel projection operator. The list of scenario for this test is Table \\@ref(tab:586)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e92995",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_list = [ (2, 2**i, 80, 512)  for i in np.arange(5,16,1)]\n",
    "pd_scenarios_list = pd.DataFrame(scenarios_list,columns = [\"D\",\"Nx\",\"Ny\",\"Nz\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840deb85",
   "metadata": {
    "label": 586,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$pd_scenarios_list, caption = \"scenario list\")%>%\n",
    "  kable_styling(full_width = T,font_size = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dbfcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_generator_.run_scenarios(scenarios_list,data_generator_Bachelier_,codpyprRegressor(set_kernel = set_sampler_kernel),data_accumulator(), **codpy_param)\n",
    "results = scenario_generator_.accumulator.get_output_datas().dropna(axis=1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f782867",
   "metadata": {},
   "source": [
    "The Table \\@ref(tab:587) output the values of this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c58fbd",
   "metadata": {
    "label": 587
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results, caption = \"codpy predictor indicators\")%>%\n",
    "  kable_styling(full_width = T,font_size = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6dd9a9",
   "metadata": {},
   "source": [
    "We output the predicted values $f_z$ against the exact ones $f(z)$, as  functions of the basket values $b(z)$ in Figure \\@ref(fig:588)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0148235",
   "metadata": {
    "fig.cap": "exact and predicted values for projection",
    "label": 588
   },
   "outputs": [],
   "source": [
    "basketzs = data_.basket(x = scenario_generator_.accumulator.get_zs())\n",
    "scenario_generator_.accumulator.plot_predicted_values(basketzs,labelx='Basket values',labely='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c37239a",
   "metadata": {},
   "source": [
    "#### Pi function\n",
    "\n",
    "We provide the same approach with the Pi function. The list of scenario for this test is Table \\@ref(tab:989)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741019e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_list = [ (2, 2**(i), 2**(i), 2**(i))  for i in np.arange(5,10,1)]\n",
    "pd_scenarios_list = pd.DataFrame(scenarios_list,columns = [\"D\",\"Nx\",\"Ny\",\"Nz\"])\n",
    "data_generator_Bachelier_iid_ = data_generator_Bachelier_iid(seed1 = 42, seed2 = 35, seed3 = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc72438",
   "metadata": {
    "label": 989
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$pd_scenarios_list, caption = \"scenario list\")%>%\n",
    "  kable_styling(latex_options = \"HOLD_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2528aead",
   "metadata": {},
   "source": [
    "The Table \\@ref(tab:590) output the values of the tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4f440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_generator_.run_scenarios(scenarios_list,data_generator_Bachelier_iid_,Pi_predictor(set_kernel = set_sampler_kernel),data_accumulator(), **codpy_param)\n",
    "results = scenario_generator_.accumulator.get_output_datas().dropna(axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aa1d60",
   "metadata": {
    "label": 590
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results, caption = \"Pi indicators\")%>%\n",
    "  kable_styling(full_width = T,font_size = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01da36a0",
   "metadata": {},
   "source": [
    "We output the predicted values $f_z$ against the exact ones $f(z)$, as  functions of the basket values $b(z)$ in Figure \\@ref(fig:591)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2499b380",
   "metadata": {
    "fig.cap": "exact and predicted values for Pi",
    "label": 591
   },
   "outputs": [],
   "source": [
    "basketzs = data_.basket(x = scenario_generator_.accumulator.get_zs())\n",
    "scenario_generator_.accumulator.plot_predicted_values(basketzs,labelx='Basket values',labely='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4636595",
   "metadata": {},
   "source": [
    "#### Pi function - discrepancy sequences\n",
    "\n",
    "We provide the same approach with the Pi function, with sharp discrepancy sequences. The list of scenario for this test is Table \\@ref(tab:592)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f7199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_list = [ (2, 2**(i), 2**(i), 2**(i))  for i in np.arange(5,10,1)]\n",
    "pd_scenarios_list = pd.DataFrame(scenarios_list,columns = [\"D\",\"Nx\",\"Ny\",\"Nz\"])\n",
    "data_generator_Bachelier_iid_ = data_generator_Bachelier_sharp(seed1 = 42, seed2 = 35, seed3 = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dda1e9",
   "metadata": {
    "label": 592
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$pd_scenarios_list, caption = \"scenario list\")%>%\n",
    "  kable_styling(full_width = T,font_size = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6247e6",
   "metadata": {},
   "source": [
    "The Table \\@ref(tab:593) output the values of the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecccf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_generator_.run_scenarios(scenarios_list,data_generator_Bachelier_iid_,Pi_predictor(set_kernel = set_sampler_kernel),data_accumulator(), **codpy_param)\n",
    "results = scenario_generator_.accumulator.get_output_datas().dropna(axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc35687d",
   "metadata": {
    "label": 593
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::kable(py$results, caption = \"Pi-sharp indicators\")%>%\n",
    "  kable_styling(full_width = T,font_size = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8804d075",
   "metadata": {},
   "source": [
    "We output the predicted values $f_z$ against the exact ones $f(z)$, as  functions of the basket values $b(z)$ in Figure \\@ref(fig:994)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82bb071",
   "metadata": {
    "fig.cap": "exact and predicted values for Pi-sharp",
    "label": 994
   },
   "outputs": [],
   "source": [
    "basketzs = data_.basket(x = scenario_generator_.accumulator.get_zs())\n",
    "scenario_generator_.accumulator.plot_predicted_values(basketzs,labelx='Basket values',labely='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7379a680",
   "metadata": {},
   "source": [
    "### Comparing methods\n",
    "\n",
    "The Figure \\@ref(fig:995) presents a benchmark for scores, computed accordingly to \\@ref(eq:RMSEper). Axis are in log-scale of the size of the training $N_x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bb8a18",
   "metadata": {
    "fig.cap": "Benchmark of scores",
    "label": 995
   },
   "outputs": [],
   "source": [
    "scenario_generator_.compare_plots(axis_field_labels = [(\"Nx\",\"scores\")],labelx='log2(Nx)',labely='scores',xscale =\"log\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029cae4a",
   "metadata": {},
   "source": [
    "The Figure \\@ref(fig:996) presents a benchmark regarding execution times in seconds. Axis are in log-scale of the size of the training $N_x$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c8dc41",
   "metadata": {
    "fig.cap": "Benchmark of execution times",
    "label": 996,
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "scenario_generator_.compare_plots(\n",
    "axis_field_labels = [(\"Nx\",\"execution_time\")],labelx='log2(Nx)',labely='scores',xscale =\"log\",yscale =\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dab398f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22fedbc9",
   "metadata": {},
   "source": [
    "## Time series\n",
    "\n",
    "This section remains to write properly.\n",
    "\n",
    "### Recurrent kernels\n",
    "\n",
    "The implemented method is defined using two integer values : H and P. H is called the historical depth, P the prediction depth. This setting defines a sliding window of size H+P over the dataset, used to define the training set. If the dataset contains N vectors, then the training set can be of size N-H-P. We can iterate the procedure, producing at each step P new predicted values. This allows, theoretically, to produce predicted values of the temporal series at any future times.\n",
    "\n",
    "This method allows to draw one trajectory, that can be considered as a iid realization of the temporal series, based on the knowledge of its history. On the following example, H and P are set to 360 days. Here the separation date is the 23/11/2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceef0cde",
   "metadata": {
    "fig.align": "center",
    "fig.cap": "The generated BTC-USD curve is the yellow one.",
    "label": 675,
    "lines_to_next_cell": 2,
    "out.width": "100%"
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::include_graphics(here::here(\"CodPyFigs\", \"1640295971717.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5f15eb",
   "metadata": {
    "fig.align": "center",
    "fig.cap": "The generated hash-rate curve is the yellow one.",
    "label": 1679,
    "out.width": "50%"
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::include_graphics(here::here(\"CodPyFigs\", \"1640295971717.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d70f652",
   "metadata": {},
   "source": [
    "This method has a lot of forecasting applications, and we do use it for professional purposes. However, in the context of temporal series forecasting, such a method faces a number of questions. For instance :\n",
    "\n",
    "- It is not clear how to generate other realizations of the studied temporal series.\n",
    "- As a consequence, it is not clear neither how to generate a pertinent mean estimator using this construction.\n",
    "\n",
    "Even if long-short term memory, or recurrent networks can produce credible generated samples, beware to unstability issues. We have no theoretical references to support these methods.\n",
    "\n",
    "### Optimal transport methods for time series\n",
    "\n",
    "Kernel methods can link easily with optimal transport theory. Using the polar factorization of maps, we can also compute explicitly the quantile of the original distribution, and extrapolate it on any random trajectory set, and we can draw \"equi-probable\" trajectories (i.e. iid realizations of the underlying process).\n",
    "\n",
    "We have also a quite clear interpretation of a mean estimator and the method is quite performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6251a1e4",
   "metadata": {
    "fig.align": "center",
    "fig.cap": "Generated sample and mean estimator for the BTC hash-rate curve.",
    "label": 1680,
    "lines_to_next_cell": 2,
    "out.width": "50%"
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "knitr::include_graphics(here::here(\"CodPyFigs\", \"1640305683779.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a159c98b",
   "metadata": {},
   "source": [
    "## Stress and reverse stress tests"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "fig.align,out.width,fig.cap,code,label,tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
